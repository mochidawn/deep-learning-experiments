{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(batch_size=48, do_augment=True, epochs=50, gpu_id=7, image_dir='/home/seanyu/datasets/cat_dog/dataset/', image_size=(120, 120, 3), is_training=1, lr=0.0001, n_classes=2, save_dir='./result', train_ratio=0.9, use_model_ckpt=None)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "#\n",
    "import os\n",
    "import glob\n",
    "import re\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import subprocess\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from time import sleep\n",
    "from tqdm import tqdm # if use notebook\n",
    "\n",
    "from threading import Thread, Event\n",
    "import queue\n",
    "\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import imgaug as ia\n",
    "from imgaug import augmenters as iaa\n",
    "\n",
    "import random\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--gpu_id', default=7)\n",
    "parser.add_argument('--image_dir', default=\"/home/seanyu/datasets/cat_dog/dataset/\")\n",
    "parser.add_argument('--save_dir', default='./result')\n",
    "parser.add_argument('--is_training', default=1, type=int)\n",
    "parser.add_argument('--batch_size', default=48, type=int)\n",
    "parser.add_argument('--do_augment', default=True, type = bool)\n",
    "parser.add_argument('--epochs', default=50, type=int)\n",
    "parser.add_argument('--lr', default=0.0001, type=float)\n",
    "parser.add_argument('--image_size', default=(120,120,3), type = int)\n",
    "parser.add_argument('--n_classes', default=2, type = int)\n",
    "parser.add_argument('--train_ratio', default=0.9, type = float)\n",
    "parser.add_argument('--use_model_ckpt', default = None, type = str)\n",
    "FLAGS = parser.parse_args([])\n",
    "print(FLAGS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = str(FLAGS.gpu_id)\n",
    "import tensorflow as tf\n",
    "\n",
    "if not os.path.exists(FLAGS.save_dir):\n",
    "    os.makedirs(FLAGS.save_dir)\n",
    "\n",
    "model_graph_name = FLAGS.save_dir + '/model.ckpt'\n",
    "    \n",
    "graphs_dir = FLAGS.save_dir + '/graphs'\n",
    "if not os.path.exists(graphs_dir):\n",
    "    os.makedirs(graphs_dir)\n",
    "\n",
    "\"\"\"  Get data \"\"\"\n",
    "d_train = FLAGS.image_dir + '/train/'\n",
    "d_test = FLAGS.image_dir + '/test1/'\n",
    "\n",
    "image_train_list = glob.glob(d_train + '*.jpg')\n",
    "image_test_list = glob.glob(d_test + '*.jpg')\n",
    "\n",
    "df_train = pd.DataFrame({'img_path': image_train_list})\n",
    "df_test = pd.DataFrame({'img_path': image_test_list})\n",
    "\n",
    "df_train['cate'] = df_train.img_path.apply(os.path.basename)\n",
    "df_train['cate'] = [i.split(\".\")[0] for i in list(df_train.cate)]\n",
    "df_train.cate = df_train.cate.replace({'dog': 0, 'cat': 1})\n",
    "\n",
    "nb_epoch = FLAGS.epochs\n",
    "\n",
    "df_train_0, df_val_0 = train_test_split(df_train[df_train['cate'] == 0], test_size = 1-FLAGS.train_ratio)\n",
    "df_train_1, df_val_1 = train_test_split(df_train[df_train['cate'] == 1], test_size = 1-FLAGS.train_ratio)\n",
    "\n",
    "df_val = pd.concat((df_val_0, df_val_1)).reset_index(drop = True)\n",
    "\n",
    "del df_val_0, df_val_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.contrib.slim as slim\n",
    "import tensorflow.contrib.slim.nets as slimNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def enqueue(queue, stop, gen_func):\n",
    "    gen = gen_func()\n",
    "    while True:\n",
    "        if stop.is_set():\n",
    "            return\n",
    "        queue.put(next(gen))\n",
    "\n",
    "class create_data_generator():\n",
    "    def __init__(self,\n",
    "                 df,\n",
    "                 open_image_handler, \n",
    "                 data_frame_handler = None,\n",
    "                 nd_inputs_preprocessing_handler = None,\n",
    "                 batch_size = 32,\n",
    "                 n_classes = 2,\n",
    "                 aug_params = None):\n",
    "        \n",
    "        self.f_readImg = open_image_handler  # how to open image\n",
    "        self.f_dataproc = data_frame_handler # how to proc original data\n",
    "        self.f_inputs_preproc = nd_inputs_preprocessing_handler # how to do image preprocessing\n",
    "        self.bz = batch_size\n",
    "        self.n_classes = n_classes\n",
    "        self.aug = aug_params\n",
    "        \n",
    "        # run functions at the begin\n",
    "        # self.df should become list of dataframe anyway\n",
    "        # if not, do the data_preproc. if yes, pass it\n",
    "        if data_frame_handler:\n",
    "            self.df = self.f_dataproc(df)\n",
    "        else:\n",
    "            self.df = df\n",
    "       \n",
    "    def get_train_data(self):\n",
    "        while True:\n",
    "            idxs = self.train_idx_queue.get()\n",
    "\n",
    "            select_list = []\n",
    "\n",
    "            for df, idx in zip(self.df, idxs):\n",
    "                select_list.append(df.iloc[idx])\n",
    "            select_list = pd.concat(select_list)\n",
    "            \n",
    "            x_ = np.array([self.f_readImg(iid) for iid in select_list.img_path], dtype=np.float32)\n",
    "            x_ = x_.astype(np.float32)\n",
    "            \"\"\" do preprocessing here\"\"\"\n",
    "            if self.f_inputs_preproc:\n",
    "                x_ = self.f_inputs_preproc(x_)\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "            \"\"\" Y out \"\"\"\n",
    "            y_ = np.array(select_list['cate'])\n",
    "            y_ = tf.keras.utils.to_categorical(y_, self.n_classes)\n",
    "\n",
    "            yield x_, y_\n",
    "        \n",
    "    def get_evaluate_data(self, target_df):\n",
    "        \n",
    "        x_ = np.array([cv_load_and_resize(i, is_training = False) for i in target_df.img_path], dtype=np.float32) # don't do augmentation!\n",
    "    \n",
    "        \"\"\" do preprocessing here\"\"\"\n",
    "        if self.f_inputs_preproc:\n",
    "            x_ = self.f_inputs_preproc(x_)\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "        \"\"\" Y out \"\"\"\n",
    "        y_ = np.array(target_df['cate'])\n",
    "        y_ = tf.keras.utils.to_categorical(y_, num_classes=self.n_classes)\n",
    "        \n",
    "        return x_, y_\n",
    "    \n",
    "    def _get_train_idx(self):\n",
    "        \"\"\" Description \n",
    "        Get training data index for each data frame in the data list\n",
    "        # note1: self.df should be list of data frame with different categories\n",
    "        # note2: if there is only 1 class (or for regression problem, should still be embraced [this_df] )\n",
    "        \"\"\"\n",
    "        len_list = [len(df) for df in self.df]\n",
    "        \n",
    "        bz_t = self.bz//len(len_list)\n",
    "        batch_num = [x//bz_t for x in len_list]\n",
    "\n",
    "        batch_nth = [0] * len(len_list)\n",
    "\n",
    "        select = [list(range(x)) for x in len_list]\n",
    "\n",
    "        for s in select:\n",
    "            random.shuffle(s)\n",
    "\n",
    "        while True:\n",
    "            idxs = []\n",
    "            for i in range(len(len_list)):\n",
    "                if batch_nth[i] >= batch_num[i]:\n",
    "                    batch_nth[i] = 0\n",
    "                    random.shuffle(select[i])\n",
    "                idx = select[i][batch_nth[i]*bz_t:(batch_nth[i]+1)*bz_t]\n",
    "                batch_nth[i] += 1\n",
    "                idxs.append(idx)\n",
    "\n",
    "            yield idxs\n",
    "    \n",
    "\n",
    "        \n",
    "    def start_train_threads(self, jobs = 1):\n",
    "        \n",
    "        self.train_queue = queue.Queue(maxsize = 10)\n",
    "        self.train_idx_queue =queue.Queue(maxsize = 100)\n",
    "        \n",
    "        ### for stop threads after training ###\n",
    "        self.events=[]\n",
    "\n",
    "        ### enqueue train index ###\n",
    "        event = Event()\n",
    "        thread = Thread(target = enqueue, \n",
    "                        args = (self.train_idx_queue, \n",
    "                                event, \n",
    "                                self._get_train_idx))\n",
    "        thread.start()\n",
    "        self.events.append(event)\n",
    "\n",
    "        ### enqueue train batch ###\n",
    "        for i in range(jobs):\n",
    "            event = Event()\n",
    "            thread = Thread(target = enqueue,args = (self.train_queue, \n",
    "                                                     event, \n",
    "                                                     self.get_train_data))\n",
    "            thread.start()\n",
    "            self.events.append(event)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping():\n",
    "    def __init__(self, patience, min_delta = 0.0001):\n",
    "        # validation loss should at least be less than current min_loss - min_delta\n",
    "        self.min_delta = min_delta \n",
    "        self.patience = patience\n",
    "        self.epoch_count = 0\n",
    "        self.min_loss = None\n",
    "        self.stop = False\n",
    "        \n",
    "    def on_epoch_end(self, val_loss, *args, **kwargs):\n",
    "        if self.min_loss is None or val_loss < self.min_loss - self.min_delta:\n",
    "            self.min_loss = val_loss\n",
    "            self.epoch_count = 0\n",
    "        else:\n",
    "            self.epoch_count += 1\n",
    "            \n",
    "        # if cumulative counts is larger than our patience, set the stop signal to True\n",
    "        if self.epoch_count >= self.patience:\n",
    "            self.stop = True\n",
    "        \n",
    "class Model_checkpoint():\n",
    "    def __init__(self, model_name, save_best_only = True):\n",
    "        self.min_loss = None\n",
    "        self.model_name = model_name\n",
    "        self.save_best_only = save_best_only\n",
    "        \n",
    "    def on_epoch_end(self, val_loss, nth_epoch, saver, sess, *args, **kwargs):\n",
    "        if self.min_loss is None or val_loss < self.min_loss:\n",
    "            self.min_loss = val_loss\n",
    "            saver.save(sess, \n",
    "                       self.model_name + '.ckpt')\n",
    "        if not self.save_best_only:\n",
    "            saver.save(sess, \n",
    "                       self.model_name + '_' + str(nth_epoch) + '.ckpt',\n",
    "                       global_step=nth_epoch)\n",
    "        \n",
    "class ReduceLROnPlateau():\n",
    "    def __init__(self, lr, factor, patience, min_lr = 1e-10):\n",
    "        self.lr = lr\n",
    "        self.factor = factor\n",
    "        self.patience = patience\n",
    "        self.min_lr = min_lr\n",
    "        self.min_loss = None\n",
    "        self.epoch_count = 0\n",
    "    \n",
    "    def on_epoch_end(self, val_loss, *args, **kwargs):\n",
    "        if self.min_loss is None or val_loss < self.min_loss:\n",
    "            epoch_count = 0\n",
    "            self.min_loss = val_loss\n",
    "        else:\n",
    "            self.epoch_count += 1\n",
    "        \n",
    "        if self.epoch_count == self.patience:\n",
    "            self.lr *= self.factor\n",
    "            self.epoch_count = 0\n",
    "            \n",
    "            if self.lr <= self.min_lr:\n",
    "                self.lr = self.min_lr\n",
    "                \n",
    "class Run_collected_functions():\n",
    "    def __init__(self, callback_dicts):\n",
    "        self.on_session_begin = callback_dicts['on_session_begin']\n",
    "        self.on_session_end = callback_dicts['on_session_end']\n",
    "        self.on_batch_begin = callback_dicts['on_batch_begin']\n",
    "        self.on_batch_end = callback_dicts['on_batch_end']\n",
    "        self.on_epoch_begin = callback_dicts['on_epoch_begin']\n",
    "        self.on_epoch_end = callback_dicts['on_epoch_end']\n",
    "        \n",
    "    def run_on_epoch_end(self, val_loss, nth_epoch = None, sess = None, saver = None):\n",
    "        for func in self.on_epoch_end:\n",
    "            getattr(func, 'on_epoch_end')(val_loss = val_loss,\n",
    "                                          nth_epoch = nth_epoch,\n",
    "                                          sess = sess,\n",
    "                                          saver = saver)\n",
    "        \n",
    "    def run_on_session_end(self, *args, **kwargs):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sometimes = lambda aug: iaa.Sometimes(0.5, aug)\n",
    "\n",
    "seq = iaa.Sequential([\n",
    "    iaa.Crop(px=(0, 16)), # crop images from each side by 0 to 16px (randomly chosen)\n",
    "    iaa.Fliplr(0.5), # horizontally flip 50% of the images\n",
    "    sometimes(iaa.Affine(\n",
    "            scale = (0.8,1.2),\n",
    "            translate_percent = (-0.2, 0.2),\n",
    "            rotate = (-30, 30),\n",
    "            order = [0, 1],\n",
    "            #cval = (0,255),\n",
    "            mode = 'wrap'\n",
    "            ))\n",
    "])\n",
    "\n",
    "def cv_load_and_resize(x, is_training = True):\n",
    "    im_w, im_h, im_c = FLAGS.image_size\n",
    "    im = cv2.imread(x)\n",
    "    im = cv2.resize(im, (im_w, im_h))\n",
    "    if FLAGS.do_augment and is_training:\n",
    "        im = seq.augment_image(im)\n",
    "    return im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_gen = create_data_generator(df=[df_train_0, df_train_1],\n",
    "                                 aug_params=seq,\n",
    "                                 batch_size=FLAGS.batch_size, \n",
    "                                 open_image_handler=cv_load_and_resize)\n",
    "data_gen.start_train_threads(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2500, 120, 120, 3)\n"
     ]
    }
   ],
   "source": [
    "x_val, y_val = data_gen.get_evaluate_data(df_val)\n",
    "print(x_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_w, im_h, im_c = FLAGS.image_size\n",
    "drp_holder = tf.placeholder(tf.float32)\n",
    "\n",
    "a_in = tf.keras.layers.Input(shape = (im_w, im_h, im_c))\n",
    "x = tf.keras.layers.Conv2D(kernel_size=(3,3), filters=32, activation=tf.nn.selu)(a_in)\n",
    "x = tf.keras.layers.MaxPooling2D(pool_size=(2,2))(x)\n",
    "\n",
    "x = tf.keras.layers.Conv2D(kernel_size=(3,3), filters=32, activation=tf.nn.selu)(x)\n",
    "x = tf.keras.layers.MaxPooling2D(pool_size=(2,2))(x)\n",
    "\n",
    "x = tf.keras.layers.Conv2D(kernel_size=(3,3), filters=64, activation=tf.nn.selu)(x)\n",
    "x = tf.keras.layers.MaxPooling2D(pool_size=(2,2))(x)\n",
    "\n",
    "x = tf.keras.layers.Flatten()(x)\n",
    "\n",
    "x = tf.keras.layers.Dense(units=64, activation=tf.nn.selu)(x)\n",
    "x = tf.keras.layers.Dropout(drp_holder)(x)\n",
    "\n",
    "x = tf.keras.layers.Dense(units=32, activation=tf.nn.selu)(x)\n",
    "x = tf.keras.layers.Dropout(drp_holder)(x)\n",
    "\n",
    "out = tf.keras.layers.Dense(units=FLAGS.n_classes, activation='linear')(x) # softmax will be at loss part\n",
    "\n",
    "y_holder = tf.placeholder(tf.float32, shape=[None, FLAGS.n_classes])\n",
    "total_loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_holder, logits=out))\n",
    "\n",
    "\n",
    "optim = tf.train.AdamOptimizer(learning_rate=FLAGS.lr)\n",
    "optim_op = optim.minimize(total_loss)\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(tf.nn.softmax(out), 1), \n",
    "                              tf.argmax(y_holder, 1))\n",
    "accuracy_op = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Training loss/acc: 1.33/0.51: 100%|██████████| 521/521 [00:29<00:00, 17.41batch/s]\n",
      "Epoch: 1, Validation loss/acc: 0.69/0.50: 100%|██████████| 53/53 [00:00<00:00, 148.81batch/s]\n",
      "Epoch: 2, Training loss/acc: 0.90/0.50: 100%|██████████| 521/521 [00:26<00:00, 19.49batch/s]\n",
      "Epoch: 2, Validation loss/acc: 0.69/0.51: 100%|██████████| 53/53 [00:00<00:00, 166.26batch/s]\n",
      "Epoch: 3, Training loss/acc: 0.83/0.50: 100%|██████████| 521/521 [00:26<00:00, 19.56batch/s]\n",
      "Epoch: 3, Validation loss/acc: 0.70/0.49: 100%|██████████| 53/53 [00:00<00:00, 152.69batch/s]\n",
      "Epoch: 4, Training loss/acc: 0.79/0.51: 100%|██████████| 521/521 [00:26<00:00, 19.33batch/s]\n",
      "Epoch: 4, Validation loss/acc: 0.70/0.50: 100%|██████████| 53/53 [00:00<00:00, 157.80batch/s]\n",
      "Epoch: 5, Training loss/acc: 0.77/0.51: 100%|██████████| 521/521 [00:26<00:00, 19.90batch/s]\n",
      "Epoch: 5, Validation loss/acc: 0.69/0.50: 100%|██████████| 53/53 [00:00<00:00, 148.80batch/s]\n",
      "Epoch: 6, Training loss/acc: 0.75/0.51: 100%|██████████| 521/521 [00:26<00:00, 19.30batch/s]\n",
      "Epoch: 6, Validation loss/acc: 0.69/0.51: 100%|██████████| 53/53 [00:00<00:00, 154.83batch/s]\n",
      "Epoch: 7, Training loss/acc: 0.74/0.51: 100%|██████████| 521/521 [00:27<00:00, 19.28batch/s]\n",
      "Epoch: 7, Validation loss/acc: 0.69/0.54: 100%|██████████| 53/53 [00:00<00:00, 151.75batch/s]\n",
      "Epoch: 8, Training loss/acc: 0.72/0.53: 100%|██████████| 521/521 [00:27<00:00, 19.01batch/s]\n",
      "Epoch: 8, Validation loss/acc: 0.66/0.60: 100%|██████████| 53/53 [00:00<00:00, 149.94batch/s]\n",
      "Epoch: 9, Training loss/acc: 0.68/0.60: 100%|██████████| 521/521 [00:27<00:00, 19.08batch/s]\n",
      "Epoch: 9, Validation loss/acc: 0.59/0.69: 100%|██████████| 53/53 [00:00<00:00, 150.04batch/s]\n",
      "Epoch: 10, Training loss/acc: 0.64/0.65: 100%|██████████| 521/521 [00:27<00:00, 18.88batch/s]\n",
      "Epoch: 10, Validation loss/acc: 0.55/0.72: 100%|██████████| 53/53 [00:00<00:00, 154.20batch/s]\n",
      "Epoch: 11, Training loss/acc: 0.61/0.68: 100%|██████████| 521/521 [00:26<00:00, 19.35batch/s]\n",
      "Epoch: 11, Validation loss/acc: 0.54/0.72: 100%|██████████| 53/53 [00:00<00:00, 151.06batch/s]\n",
      "Epoch: 12, Training loss/acc: 0.59/0.69: 100%|██████████| 521/521 [00:26<00:00, 19.47batch/s]\n",
      "Epoch: 12, Validation loss/acc: 0.51/0.74: 100%|██████████| 53/53 [00:00<00:00, 149.29batch/s]\n",
      "Epoch: 13, Training loss/acc: 0.56/0.72: 100%|██████████| 521/521 [00:26<00:00, 19.66batch/s]\n",
      "Epoch: 13, Validation loss/acc: 0.49/0.76: 100%|██████████| 53/53 [00:00<00:00, 144.24batch/s]\n",
      "Epoch: 14, Training loss/acc: 0.54/0.73: 100%|██████████| 521/521 [00:26<00:00, 19.30batch/s]\n",
      "Epoch: 14, Validation loss/acc: 0.48/0.76: 100%|██████████| 53/53 [00:00<00:00, 146.42batch/s]\n",
      "Epoch: 15, Training loss/acc: 0.53/0.74: 100%|██████████| 521/521 [00:26<00:00, 19.90batch/s]\n",
      "Epoch: 15, Validation loss/acc: 0.45/0.79: 100%|██████████| 53/53 [00:00<00:00, 154.81batch/s]\n",
      "Epoch: 16, Training loss/acc: 0.51/0.75: 100%|██████████| 521/521 [00:26<00:00, 19.75batch/s]\n",
      "Epoch: 16, Validation loss/acc: 0.43/0.80: 100%|██████████| 53/53 [00:00<00:00, 156.82batch/s]\n",
      "Epoch: 17, Training loss/acc: 0.50/0.76: 100%|██████████| 521/521 [00:25<00:00, 20.36batch/s]\n",
      "Epoch: 17, Validation loss/acc: 0.44/0.80: 100%|██████████| 53/53 [00:00<00:00, 164.12batch/s]\n",
      "Epoch: 18, Training loss/acc: 0.49/0.76: 100%|██████████| 521/521 [00:26<00:00, 19.65batch/s]\n",
      "Epoch: 18, Validation loss/acc: 0.41/0.81: 100%|██████████| 53/53 [00:00<00:00, 162.54batch/s]\n",
      "Epoch: 19, Training loss/acc: 0.49/0.77: 100%|██████████| 521/521 [00:28<00:00, 18.48batch/s]\n",
      "Epoch: 19, Validation loss/acc: 0.43/0.80: 100%|██████████| 53/53 [00:00<00:00, 153.80batch/s]\n",
      "Epoch: 20, Training loss/acc: 0.48/0.77: 100%|██████████| 521/521 [00:27<00:00, 18.76batch/s]\n",
      "Epoch: 20, Validation loss/acc: 0.41/0.81: 100%|██████████| 53/53 [00:00<00:00, 146.32batch/s]\n",
      "Epoch: 21, Training loss/acc: 0.47/0.78: 100%|██████████| 521/521 [00:27<00:00, 19.09batch/s]\n",
      "Epoch: 21, Validation loss/acc: 0.44/0.80: 100%|██████████| 53/53 [00:00<00:00, 147.25batch/s]\n",
      "Epoch: 22, Training loss/acc: 0.47/0.78: 100%|██████████| 521/521 [00:26<00:00, 19.70batch/s]\n",
      "Epoch: 22, Validation loss/acc: 0.42/0.80: 100%|██████████| 53/53 [00:00<00:00, 144.57batch/s]\n",
      "Epoch: 23, Training loss/acc: 0.46/0.78: 100%|██████████| 521/521 [00:26<00:00, 19.69batch/s]\n",
      "Epoch: 23, Validation loss/acc: 0.39/0.82: 100%|██████████| 53/53 [00:00<00:00, 150.76batch/s]\n",
      "Epoch: 24, Training loss/acc: 0.45/0.79: 100%|██████████| 521/521 [00:27<00:00, 18.69batch/s]\n",
      "Epoch: 24, Validation loss/acc: 0.40/0.82: 100%|██████████| 53/53 [00:00<00:00, 148.16batch/s]\n",
      "Epoch: 25, Training loss/acc: 0.44/0.80: 100%|██████████| 521/521 [00:26<00:00, 19.42batch/s]\n",
      "Epoch: 25, Validation loss/acc: 0.42/0.81: 100%|██████████| 53/53 [00:00<00:00, 159.80batch/s]\n",
      "Epoch: 26, Training loss/acc: 0.44/0.80: 100%|██████████| 521/521 [00:26<00:00, 19.74batch/s]\n",
      "Epoch: 26, Validation loss/acc: 0.41/0.82: 100%|██████████| 53/53 [00:00<00:00, 160.67batch/s]\n",
      "Epoch: 27, Training loss/acc: 0.44/0.80: 100%|██████████| 521/521 [00:27<00:00, 19.11batch/s]\n",
      "Epoch: 27, Validation loss/acc: 0.40/0.82: 100%|██████████| 53/53 [00:00<00:00, 152.84batch/s]\n",
      "Epoch: 28, Training loss/acc: 0.43/0.81: 100%|██████████| 521/521 [00:26<00:00, 20.00batch/s]\n",
      "Epoch: 28, Validation loss/acc: 0.37/0.83: 100%|██████████| 53/53 [00:00<00:00, 148.92batch/s]\n",
      "Epoch: 29, Training loss/acc: 0.42/0.81: 100%|██████████| 521/521 [00:27<00:00, 18.61batch/s]\n",
      "Epoch: 29, Validation loss/acc: 0.37/0.85: 100%|██████████| 53/53 [00:00<00:00, 151.14batch/s]\n",
      "Epoch: 30, Training loss/acc: 0.42/0.81: 100%|██████████| 521/521 [00:26<00:00, 19.86batch/s]\n",
      "Epoch: 30, Validation loss/acc: 0.39/0.83: 100%|██████████| 53/53 [00:00<00:00, 159.80batch/s]\n",
      "Epoch: 31, Training loss/acc: 0.41/0.81: 100%|██████████| 521/521 [00:26<00:00, 19.64batch/s]\n",
      "Epoch: 31, Validation loss/acc: 0.39/0.83: 100%|██████████| 53/53 [00:00<00:00, 158.24batch/s]\n",
      "Epoch: 32, Training loss/acc: 0.41/0.82: 100%|██████████| 521/521 [00:27<00:00, 19.27batch/s]\n",
      "Epoch: 32, Validation loss/acc: 0.36/0.84: 100%|██████████| 53/53 [00:00<00:00, 163.02batch/s]\n",
      "Epoch: 33, Training loss/acc: 0.41/0.82: 100%|██████████| 521/521 [00:26<00:00, 19.40batch/s]\n",
      "Epoch: 33, Validation loss/acc: 0.37/0.84: 100%|██████████| 53/53 [00:00<00:00, 143.58batch/s]\n",
      "Epoch: 34, Training loss/acc: 0.40/0.82: 100%|██████████| 521/521 [00:26<00:00, 19.66batch/s]\n",
      "Epoch: 34, Validation loss/acc: 0.35/0.84: 100%|██████████| 53/53 [00:00<00:00, 134.97batch/s]\n",
      "Epoch: 35, Training loss/acc: 0.40/0.82: 100%|██████████| 521/521 [00:26<00:00, 19.61batch/s]\n",
      "Epoch: 35, Validation loss/acc: 0.37/0.84: 100%|██████████| 53/53 [00:00<00:00, 156.38batch/s]\n",
      "Epoch: 36, Training loss/acc: 0.40/0.82: 100%|██████████| 521/521 [00:26<00:00, 19.63batch/s]\n",
      "Epoch: 36, Validation loss/acc: 0.36/0.85: 100%|██████████| 53/53 [00:00<00:00, 162.18batch/s]\n",
      "Epoch: 37, Training loss/acc: 0.40/0.82: 100%|██████████| 521/521 [00:26<00:00, 19.33batch/s]\n",
      "Epoch: 37, Validation loss/acc: 0.35/0.85: 100%|██████████| 53/53 [00:00<00:00, 158.29batch/s]\n",
      "Epoch: 38, Training loss/acc: 0.39/0.83: 100%|██████████| 521/521 [00:26<00:00, 19.56batch/s]\n",
      "Epoch: 38, Validation loss/acc: 0.36/0.85: 100%|██████████| 53/53 [00:00<00:00, 150.09batch/s]\n",
      "Epoch: 39, Training loss/acc: 0.38/0.83: 100%|██████████| 521/521 [00:27<00:00, 18.73batch/s]\n",
      "Epoch: 39, Validation loss/acc: 0.35/0.85: 100%|██████████| 53/53 [00:00<00:00, 151.59batch/s]\n",
      "Epoch: 40, Training loss/acc: 0.38/0.83: 100%|██████████| 521/521 [00:27<00:00, 18.91batch/s]\n",
      "Epoch: 40, Validation loss/acc: 0.34/0.85: 100%|██████████| 53/53 [00:00<00:00, 160.68batch/s]\n",
      "Epoch: 41, Training loss/acc: 0.38/0.83: 100%|██████████| 521/521 [00:27<00:00, 19.12batch/s]\n",
      "Epoch: 41, Validation loss/acc: 0.36/0.84: 100%|██████████| 53/53 [00:00<00:00, 153.74batch/s]\n",
      "Epoch: 42, Training loss/acc: 0.38/0.83: 100%|██████████| 521/521 [00:26<00:00, 19.60batch/s]\n",
      "Epoch: 42, Validation loss/acc: 0.35/0.84: 100%|██████████| 53/53 [00:00<00:00, 153.17batch/s]\n",
      "Epoch: 43, Training loss/acc: 0.38/0.84: 100%|██████████| 521/521 [00:26<00:00, 20.03batch/s]\n",
      "Epoch: 43, Validation loss/acc: 0.36/0.85: 100%|██████████| 53/53 [00:00<00:00, 142.93batch/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 44, Training loss/acc: 0.37/0.84: 100%|██████████| 521/521 [00:28<00:00, 18.55batch/s]\n",
      "Epoch: 44, Validation loss/acc: 0.33/0.86: 100%|██████████| 53/53 [00:00<00:00, 144.74batch/s]\n",
      "Epoch: 45, Training loss/acc: 0.37/0.84: 100%|██████████| 521/521 [00:27<00:00, 19.15batch/s]\n",
      "Epoch: 45, Validation loss/acc: 0.35/0.85: 100%|██████████| 53/53 [00:00<00:00, 151.25batch/s]\n",
      "Epoch: 46, Training loss/acc: 0.36/0.84: 100%|██████████| 521/521 [00:27<00:00, 19.06batch/s]\n",
      "Epoch: 46, Validation loss/acc: 0.34/0.85: 100%|██████████| 53/53 [00:00<00:00, 152.98batch/s]\n",
      "Epoch: 47, Training loss/acc: 0.36/0.84: 100%|██████████| 521/521 [00:27<00:00, 18.91batch/s]\n",
      "Epoch: 47, Validation loss/acc: 0.34/0.86: 100%|██████████| 53/53 [00:00<00:00, 146.38batch/s]\n",
      "Epoch: 48, Training loss/acc: 0.36/0.84: 100%|██████████| 521/521 [00:27<00:00, 18.81batch/s]\n",
      "Epoch: 48, Validation loss/acc: 0.36/0.85: 100%|██████████| 53/53 [00:00<00:00, 140.22batch/s]\n",
      "Epoch: 49, Training loss/acc: 0.35/0.85: 100%|██████████| 521/521 [00:27<00:00, 19.07batch/s]\n",
      "Epoch: 49, Validation loss/acc: 0.34/0.85: 100%|██████████| 53/53 [00:00<00:00, 140.78batch/s]\n",
      "Epoch: 50, Training loss/acc: 0.35/0.85: 100%|██████████| 521/521 [00:28<00:00, 18.24batch/s]\n",
      "Epoch: 50, Validation loss/acc: 0.33/0.86: 100%|██████████| 53/53 [00:00<00:00, 145.10batch/s]\n"
     ]
    }
   ],
   "source": [
    "n_batch = len(df_train) // FLAGS.batch_size + 1 # standard way - look all samples per epoch\n",
    "\n",
    "early_stop = EarlyStopping(patience=10)\n",
    "model_checkpt = Model_checkpoint(model_name=model_graph_name, save_best_only=True)\n",
    "reduce_lr = ReduceLROnPlateau(lr=FLAGS.lr, factor=0.5, patience=3)\n",
    "\n",
    "callback_dict = {\n",
    "    'on_session_begin':[], # start of a session\n",
    "    'on_batch_begin':[], # start of a training batch\n",
    "    'on_batch_end':[], # end of a training batch\n",
    "    'on_epoch_begin':[], # start of a epoch\n",
    "    'on_epoch_end':[early_stop, reduce_lr], # end of a epoch\n",
    "    'on_session_end':[] # end of a session\n",
    "    }\n",
    "callback_manager = Run_collected_functions(callback_dict)\n",
    "\n",
    "\n",
    "# -------------------------- #\n",
    "global_train_loss, global_train_acc = [], []\n",
    "global_valid_loss, global_valid_acc = [], []\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    saver = tf.train.Saver()\n",
    "    sess.run([tf.global_variables_initializer()])\n",
    "    \n",
    "    \"\"\"\n",
    "    epoch_bar = tqdm(range(FLAGS.epochs), \n",
    "                     desc = \"Train epoch\", \n",
    "                     unit = \"Epoch\")\n",
    "    \"\"\"\n",
    "    epoch_bar = range(FLAGS.epochs)\n",
    "    for i in epoch_bar:\n",
    "        \"\"\"\n",
    "        if i == 0:\n",
    "            epoch_bar.set_description(\"Training loss/acc: %.2f/%.2f ;Validation: %.2f/%.2f\" % \n",
    "                                  (0.0,0.0,0.0,0.0))\n",
    "        else:\n",
    "            epoch_bar.set_description(\"Training loss/acc: %.2f/%.2f ;Validation: %.2f/%.2f\" % \n",
    "                                  (global_train_loss[-1], global_train_acc[-1], global_valid_loss[-1], global_valid_acc[-1]))\n",
    "        \"\"\"\n",
    "        train_epoch_loss, train_epoch_acc = [], []\n",
    "        train_batch_bar = tqdm(range(n_batch), \n",
    "                               desc = \"Training batch\", \n",
    "                               unit = \"batch\", \n",
    "                               leave = True)\n",
    "        for j in train_batch_bar:\n",
    "            x_, y_ = data_gen.train_queue.get()\n",
    "            \n",
    "            batch_loss, batch_acc, _ = sess.run([total_loss, accuracy_op, optim_op], \n",
    "                                                feed_dict = {a_in: x_, \n",
    "                                                                     y_holder: y_, \n",
    "                                                                     tf.keras.backend.learning_phase(): 1,\n",
    "                                                                     drp_holder: 0.2})\n",
    "            train_epoch_loss.append(batch_loss)\n",
    "            train_epoch_acc.append(batch_acc)\n",
    "            current_train_loss = np.mean(train_epoch_loss)\n",
    "            current_train_acc = np.mean(train_epoch_acc)\n",
    "            train_batch_bar.set_description('Epoch: %i, Training loss/acc: %.2f/%.2f' % (int(i+1),current_train_loss, current_train_acc))\n",
    "            \n",
    "        \n",
    "        global_train_loss.append(current_train_loss)\n",
    "        global_train_acc.append(current_train_acc)\n",
    "        \n",
    "        valid_epoch_loss, valid_epoch_acc = [], []\n",
    "        \n",
    "        valid_step = range(len(df_val) // FLAGS.batch_size + 1)\n",
    "        valid_batch_bar = tqdm(valid_step, \n",
    "                               desc = \"Valid batch\", \n",
    "                               unit = \"batch\", leave = True)\n",
    "        \n",
    "        #valid_batch_bar = range(len(df_val) // FLAGS.batch_size + 1)\n",
    "        for j in valid_batch_bar:\n",
    "            this_val_loss, this_val_acc = sess.run([total_loss, accuracy_op], \n",
    "                                                       feed_dict = {a_in: x_val[j*FLAGS.batch_size : (j+1) * FLAGS.batch_size], \n",
    "                                                                            y_holder: y_val[j*FLAGS.batch_size : (j+1) * FLAGS.batch_size],\n",
    "                                                                            tf.keras.backend.learning_phase(): 0,\n",
    "                                                                            drp_holder: 0.0} )\n",
    "            valid_epoch_loss.append(this_val_loss)\n",
    "            valid_epoch_acc.append(this_val_acc)\n",
    "            \n",
    "            if j == np.max(valid_step):\n",
    "                current_valid_loss = np.mean(valid_epoch_loss)\n",
    "                current_valid_acc = np.mean(valid_epoch_acc)\n",
    "                valid_batch_bar.set_description('Epoch: %i, Validation loss/acc: %.2f/%.2f' % (int(i+1), current_valid_loss, current_valid_acc))\n",
    "\n",
    "        # \n",
    "        global_valid_loss.append(current_valid_loss)\n",
    "        global_valid_acc.append(current_valid_acc)\n",
    "        \n",
    "        #\n",
    "        callback_manager.run_on_epoch_end(val_loss = current_valid_loss,\n",
    "                                          sess = sess,\n",
    "                                          saver = saver,\n",
    "                                          nth_epoch = i)\n",
    "        if early_stop.stop:\n",
    "            print(\"EarlyStop!\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAIABJREFUeJzt3Xd4lFXe//H3SYEAAgkERYoUBYXQ\nCYggIqIuRcGuCCrWlZ+KrMoj+rCgPpe7urLYy1qwNxbFimIDAbEBIkWQJkpAISCE0Ak5vz++CSmk\nTJJJJjP5vK7rviYzc2fm3Bg/c+bc5/4e571HREQiS1SoGyAiIsGncBcRiUAKdxGRCKRwFxGJQAp3\nEZEIpHAXEYlACncRkQikcBcRiUAKdxGRCBQTqjdOTEz0zZs3D9Xbi4iEpQULFmzx3jcobr+QhXvz\n5s2ZP39+qN5eRCQsOed+DWQ/DcuIiEQghbuISARSuIuIRKCQjbmLSMU7cOAAKSkp7N27N9RNkWLE\nxcXRpEkTYmNjS/X7CneRKiQlJYXatWvTvHlznHOhbo4UwnvP1q1bSUlJoUWLFqV6DQ3LiFQhe/fu\npX79+gr2Ss45R/369cv0DUvhLlLFKNjDQ1n/O4VduC9dCuPGwdatoW6JiEjlFXbhvmoV3Hsv/PZb\nqFsiIiW1fft2nnjiiVL97sCBA9m+fXuR+4wfP57PPvusVK+fX/PmzdmyZUtQXisUwi7c69e32z//\nDG07RKTkigr3jIyMIn93+vTpxMfHF7nPPffcw+mnn17q9kWSsAv3evXsVsMyIuFn7NixrFmzhk6d\nOjFmzBhmzZpF7969GTx4MG3btgXgnHPOoWvXriQlJfH0008f+t3snvS6deto06YN1157LUlJSZx5\n5pns2bMHgBEjRjB16tRD+0+YMIEuXbrQvn17VqxYAUBqaipnnHEGSUlJXHPNNTRr1qzYHvqkSZNo\n164d7dq146GHHgJg165dDBo0iI4dO9KuXTvefPPNQ8fYtm1bOnTowG233Rbcf8ASCLupkNk9d4W7\nSNmMHg2LFgX3NTt1gqzsK9B9993H0qVLWZT1xrNmzWLhwoUsXbr00JS/yZMnU69ePfbs2UO3bt04\n//zzqZ/9P36WVatW8frrr/PMM89w0UUX8dZbbzF8+PDD3i8xMZGFCxfyxBNPMHHiRJ599lnuvvtu\nTjvtNO644w4+/vhjnnvuuSKPacGCBTz//PN8++23eO858cQT6dOnD2vXrqVRo0Z8+OGHAKSlpbF1\n61amTZvGihUrcM4VO4xUnsK2565hGZHI0L179zxzuR955BE6duxIjx49WL9+PatWrTrsd1q0aEGn\nTp0A6Nq1K+vWrSvwtc8777zD9pk7dy6XXHIJAP379ychIaHI9s2dO5dzzz2XWrVqccQRR3Deeecx\nZ84c2rdvz6effsrtt9/OnDlzqFu3LnXr1iUuLo6rr76at99+m5o1a5b0nyNowq7nXr061KqlnrtI\nWRXVw65ItWrVOvTzrFmz+Oyzz/j666+pWbMmp556aoFzvatXr37o5+jo6EPDMoXtFx0dXeyYfkm1\nbt2ahQsXMn36dMaNG0e/fv0YP3483333HZ9//jlTp07lscce44svvgjq+wYq7HruYEMzCneR8FO7\ndm3S09MLfT4tLY2EhARq1qzJihUr+Oabb4Lehl69ejFlyhQAPvnkE7Zt21bk/r179+add95h9+7d\n7Nq1i2nTptG7d282btxIzZo1GT58OGPGjGHhwoXs3LmTtLQ0Bg4cyIMPPsiPP/4Y9PYHKux67qBw\nFwlX9evXp1evXrRr144BAwYwaNCgPM/379+fp556ijZt2nD88cfTo0ePoLdhwoQJDB06lJdffpmT\nTjqJhg0bUrt27UL379KlCyNGjKB79+4AXHPNNXTu3JkZM2YwZswYoqKiiI2N5cknnyQ9PZ0hQ4aw\nd+9evPdMmjQp6O0PlPPeh+SNk5OTfWkX6zjjDNi1C+bNC3KjRCLc8uXLadOmTaibEVL79u0jOjqa\nmJgYvv76a0aOHHnoBG9lU9B/L+fcAu99cnG/G5Y993r1dBGTiJTOb7/9xkUXXURmZibVqlXjmWee\nCXWTykVYhruGZUSktFq1asUPP/wQ6maUu7A9obptG2RmhrolIiKVU1iGe716FuxpaaFuiYhI5RSW\n4a6rVEVEiqZwFxGJQGEd7ipBIBL5jjjiCAA2btzIBRdcUOA+p556KsVNrX7ooYfYvXv3ofuBlBAO\nxF133cXEiRPL/DrBFpbhrsqQIlVPo0aNDlV8LI384R5ICeFwFpbhrmEZkfA0duxYHn/88UP3s3u9\nO3fupF+/fofK87777ruH/e66deto164dAHv27OGSSy6hTZs2nHvuuXlqy4wcOZLk5GSSkpKYMGEC\nYMXINm7cSN++fenbty+QdzGOgkr6FlVauDCLFi2iR48edOjQgXPPPfdQaYNHHnnkUBng7KJlX375\nJZ06daJTp0507ty5yLIMpRGW89zj48E5DcuIlEkIav5efPHFjB49mhtuuAGAKVOmMGPGDOLi4pg2\nbRp16tRhy5Yt9OjRg8GDBxe6juiTTz5JzZo1Wb58OYsXL6ZLly6Hnrv33nupV68eBw8epF+/fixe\nvJhRo0YxadIkZs6cSWJiYp7XKqykb0JCQsClhbNdfvnlPProo/Tp04fx48dz991389BDD3Hffffx\nyy+/UL169UNDQRMnTuTxxx+nV69e7Ny5k7i4uID/mQMRlj336GgLePXcRcJL586d2bx5Mxs3buTH\nH38kISGBpk2b4r3nzjvvpEOHDpx++uls2LCBTZs2Ffo6s2fPPhSyHTp0oEOHDoeemzJlCl26dKFz\n584sW7aMn376qcg2FVbSFwIvLQxW9Gz79u306dMHgCuuuILZs2cfauOwYcN45ZVXiImxPnWvXr24\n5ZZbeOSRR9i+ffuhx4MlLHvuoKtURcosRDV/L7zwQqZOncoff/zBxRdfDMCrr75KamoqCxYsIDY2\nlubNmxdY6rc4v/zyCxMnTuT7778nISGBESNGlOp1sgVaWrg4H374IbNnz+b999/n3nvvZcmSJYwd\nO5ZBgwYxffp0evXqxYwZMzjhhBNK3db8wrLnDhbuGpYRCT8XX3wxb7zxBlOnTuXCCy8ErNd75JFH\nEhsby8yZM/n111+LfI1TTjmF1157DYClS5eyePFiAHbs2EGtWrWoW7cumzZt4qOPPjr0O4WVGy6s\npG9J1a1bl4SEhEO9/pdffpk+ffqQmZnJ+vXr6du3L/fffz9paWns3LmTNWvW0L59e26//Xa6det2\naBnAYCm25+6cmwycBWz23rcr4PlhwO2AA9KBkd77ci9iXL8+FPGtTUQqqaSkJNLT02ncuDFHH300\nAMOGDePss8+mffv2JCcnF9uDHTlyJFdeeSVt2rShTZs2dO3aFYCOHTvSuXNnTjjhBJo2bUqvXr0O\n/c51111H//79adSoETNnzjz0eGElfYsaginMiy++yPXXX8/u3btp2bIlzz//PAcPHmT48OGkpaXh\nvWfUqFHEx8fz97//nZkzZxIVFUVSUhIDBgwo8fsVpdiSv865U4CdwEuFhHtPYLn3fptzbgBwl/f+\nxOLeuCwlfwEuuwzmzoVffin1S4hUOSr5G17KteSv9362c655Ec/nrqr+DdCkuNcMBo25i4gULthj\n7lcDHxW7VxDUrw/p6XDgQEW8m4hIeAlauDvn+mLhfnsR+1znnJvvnJufmppapvfLvkpVJ1VFSiZU\nq69JyZT1v1NQwt051wF4FhjivS90sMR7/7T3Ptl7n9ygQYMyvaeuUhUpubi4OLZu3aqAr+S892zd\nurVMFzaVeZ67c+4Y4G3gMu/9yrK+XqBUPEyk5Jo0aUJKSgpl/eYs5S8uLo4mTUp/CjOQqZCvA6cC\nic65FGACEAvgvX8KGA/UB57IulQ4I5AzuWWlnrtIycXGxtKiRYtQN0MqQCCzZYYW8/w1wDVBa1GA\nVBlSRKRwYX2FKmhYRkSkIGEb7kccAbGx6rmLiBQkbMPdORuaUbiLiBwubMMddJWqiEhhwj7cNeYu\nInK4sA939dxFRA4X1uGuMXcRkYKFdbhrWEZEpGBhH+5798Lu3aFuiYhI5RLW4a6rVEVEChbW4a76\nMiIiBYuIcNe4u4hIXhER7uq5i4jkFdbhrjF3EZGChXW4a1hGRKRgYR3u1atDrVrquYuI5BfW4Q66\nSlVEpCBhH+66SlVE5HAREe7quYuI5KVwFxGJQGEf7hpzFxE5XNiHe/aYe2ZmqFsiIlJ5RES4Z2bC\njh2hbomISOUR9uGuq1RFRA4X9uGuq1RFRA4XMeGunruISA6Fu4hIBAr7cNeYu4jI4cI+3BMSwDmN\nuYuI5Bb24R4dDfHx6rmLiOQW9uEOukpVRCS/YsPdOTfZObfZObe0kOedc+4R59xq59xi51yX4Dez\naKoMKSKSVyA99xeA/kU8PwBolbVdBzxZ9maVjIqHiYjkVWy4e+9nA0X1i4cAL3nzDRDvnDs6WA0M\nhIZlRETyCsaYe2Ngfa77KVmPHcY5d51zbr5zbn5qamoQ3tpoWEZEJK8KPaHqvX/ae5/svU9u0KBB\n0F63fn1IS4OMjKC9pIhIWAtGuG8Amua63yTrsQqj+jIiInkFI9zfAy7PmjXTA0jz3v8ehNcNmK5S\nFRHJK6a4HZxzrwOnAonOuRRgAhAL4L1/CpgODARWA7uBK8ursYVRz11EJK9iw917P7SY5z1wQ9Ba\nVAoqHiYiklfEXKEKCncRkWwREe4alhERySsiwr12bYiJUc9dRCRbRIS7cypBICKSW0SEO6gEgYhI\nbhET7ipBICKSI6LCXT13ERETMeGuYRkRkRwRE+4alhERyRFR4b5nj20iIlVdRIU7aGhGRAQiKNyz\nSxBoaEZEJILCXT13EZEcCncRkQgUMeHetCnExsKcOaFuiYhI6EVMuMfHw8UXw/PPQ3p6qFsjIhJa\nERPuADfdZMH+4ouhbomISGhFVLh37w4nngiPPgqZmaFujYhI6ERUuAOMGgUrV8Knn4a6JSIioRNx\n4X7BBdCwITzySKhbIiISOhEX7tWqwfXXw/TpsGpVqFsjIhIaERfuAH/9q02LfOyxULdERCQ0IjLc\nGzaEiy7StEgRqboiMtzBTqxqWqSIVFURG+6aFikiVVnEhjvYRU2aFikiVVFEh/uFF2papIhUTREd\n7poWKSJVVUSHO+RMixw/HrwPdWtERCpGxId7w4Ywbhy88YadXBURqQoCCnfnXH/n3M/OudXOubEF\nPH+Mc26mc+4H59xi59zA4De19MaNgyFD4JZbYNasULdGRKT8FRvuzrlo4HFgANAWGOqca5tvt3HA\nFO99Z+AS4IlgN7QsoqLgpZegVSs7yfrbb6FukYhI+Qqk594dWO29X+u93w+8AQzJt48H6mT9XBfY\nGLwmBkedOvDOO7B/P5x7LuzZE+oWiYiUn0DCvTGwPtf9lKzHcrsLGO6cSwGmAzcFpXVBdvzx8Mor\nsHChzaLRCVYRiVTBOqE6FHjBe98EGAi87Jw77LWdc9c55+Y75+anpqYG6a1L5uyz4e67bZhGJ1hF\nJFIFEu4bgKa57jfJeiy3q4EpAN77r4E4IDH/C3nvn/beJ3vvkxs0aFC6FgfBuHFwzjl2gvWLL0LW\nDBGRchNIuH8PtHLOtXDOVcNOmL6Xb5/fgH4Azrk2WLiHpmsegKgoKyjWujWceSbceCOE6IuEiEi5\nKDbcvfcZwI3ADGA5NitmmXPuHufc4KzdbgWudc79CLwOjPC+co9o16kDs2fb2PtTT8Gxx8I//6kT\nrSISGVyoMjg5OdnPnz8/JO+d34oVMHYsvPsuNGkC994Lw4dbD19EpDJxzi3w3icXt5/iCzjhBJsm\nOWuWXdF6xRXQtSt89lmoWyYiUjoK91z69IFvv4VXX4Vt2+CMM+Avf4FFi0LdMhGRklG45xMVBZde\nCj//DP/+N3z/PXTpApdfDr/+GurWiYgERuFeiOrVbarkmjUwZgxMmWIXQd12G/zxR6hbJyJSNIV7\nMRIS4P77bUWnSy6BSZOgWTO49lpYvjzUrRMRKZjCPUDHHAMvvGAza666ysoYtG1rV7x++aVKGYhI\n5aJwL6HWreHJJ62y5F13wTffwKmn2oLc06Yp5EWkclC4l1KDBjBhgoX8U0/B9u1w3nl28vXddxXy\nIhJaCvcyqlHDlvJbvtxKGqSnW92a5GR4/32FvIiEhsI9SGJibLrkihXw/PPWkx88GLp1g+++C3Xr\nRKSqUbgHWUwMjBhhIf/cc7Bpk4X81q2hbpmIVCUK93ISG2uzat5/34L9xhtD3SIRqUoU7uWsUycY\nPx7eeAOmTg11a0Skqqi64e497NsHBw+W+1uNHWuFyEaOhM2by/3tRESICXUDSmzbNli/HmrXztmq\nV895/sABWLcOVq2yy0pXrYLVq2HLFti1C3buzLnNyIAjjoCePeGUU2zr1g3i4oLa5NhYm0nTpYsF\n/NSp4FxQ30JEJI/wC/fPPoOLLsr7WGysrb5Ro4YVfsnIyHmubl1o1QqOPtqCvFatnNtatWDjRpgz\nx9beA/ug6N4dOna0Xv2+fbbt35/T009IgMREm+yefXvUUfZ7MQX/kyYlwf/9H9x+O7z+uhUnExEp\nL+G3WMeGDVaXd8cOm1SefZuebj3yxo0tzFu3ttvExMC6yVu3wldf2fJMc+bYdJdq1Szsc29RUfbt\nITXVev+5nXkmvPWWfXgU4OBBOPlkqzi5dCk0alTywxeRqi3QxTrCL9wrk717bbgnNdUKzNx6qw2u\nf/ih9eYL8PPPdpK1Xz+bSaPhGREpCa3EVBHi4mxdvs6dYfRoKy6zZIl1zwsp/n788bZW64cfWiEy\nEZHyoHAPpsGD4ZNPbEpMz54W9AUYNcpWfbrxRhthEhEJNoV7sPXubeP2YLNv5s49bJeoKHjzTVuv\nddAgG6oREQkmhXt5aN8e5s2DI4+0hVg/+eSwXY46CmbMgOhoW6d148YQtFNEIpbCvbw0a2a99pYt\n4YYbIDPzsF2OOw6mT7dzsgMHQlpaCNopIhFJ4V6esou+r14NH3xQ4C5du8Lbb8OyZVYqeN++Cm6j\niEQkhXt5O+88W6Nv0qRCdznzTJs5M2sWXHZZhVREEJEIp3AvbzExcPPNNg9+wYJCdxs2DCZOhP/+\n12ZVapEPESkLhXtFuPpqq4Hz4INF7nbrrXDLLfDYY7Y+q4hIaSncK0LdunDNNTb/MSWlyF0feACu\nvBLuucd68iIipaFwryijRtmMmcceK3K3qCh45hm48EIYMwaefrqC2iciEUXhXlGaN4fzz4f//Ofw\ngmP5REfDK6/Y9Mjrr4dXX62YJopI5FC4V6RbbrGVswMoKlOtmtV979MHrrgC3n23/JsnIpEjoHB3\nzvV3zv3snFvtnBtbyD4XOed+cs4tc869FtxmRogePeCkk+zEagDzHWvUgPfes7nwF11kpexFRAJR\nbLg756KBx4EBQFtgqHOubb59WgF3AL2890nA6HJoa2S45RZYu9ZSOwC1a8NHH1k1ySFD4L77rIS9\niEhRAum5dwdWe+/Xeu/3A28AQ/Ltcy3wuPd+G4D3XiuFFuacc2z8vYiLmvKrV8/K0/TuDXfcYZUN\nxo+39UVERAoSSLg3Btbnup+S9VhurYHWzrmvnHPfOOf6F/RCzrnrnHPznXPzU1NTS9ficJd9UdPc\nufDddwH/WsOG8PHH9it9+9qSfc2awW23qeiYiBwuWCdUY4BWwKnAUOAZ51x8/p28909775O998kN\nClmpqEq46ipb8/WBB0r8q926WS2apUvtS8CDD0KLFjYJR0QkWyDhvgFomut+k6zHcksB3vPeH/De\n/wKsxMJeClKnjvXep06Fl18u1UskJdl0yZUrrSd//fV2X0QEAgv374FWzrkWzrlqwCVA/rOB72C9\ndpxzidgwzdogtjPyjB8Pp54K110HCxeW+mWOPRbeeccCfsSIgM/TikiEKzbcvfcZwI3ADGA5MMV7\nv8w5d49zbnDWbjOArc65n4CZwBjvvU73FSUmxsoRJCZa5cgtW0r9UnFxNg++SxebMjlzZhDbKSJh\nyfkQlR9MTk728+fPD8l7Vyrff2/TYHr3tjmPMTGlfqmtW+2ip19/hc8/h+7dg9hOEakUnHMLvPfJ\nxe2nK1RDrVs3eOIJu0Lpf/+3TC9Vv75NmTzySBgwwE66ikjVpHCvDK66ys6I/utfVtC9DBo1gk8/\nherVbRGQ1auD1EYRCSsK98ri4YetNMGVV5a5y92ypQX8vn22VveNN9pQjYhUHQr3yiK7Uljt2lYO\n8oEHytTtTkqy4fxhw6xs8HHH2efGzz8Hsc0iUmkp3CuTRo1s2ktiIvzP/0CrVtChgy3L9OOPJV57\nr2VLePZZWLMG/t//s8k5bdrYjJpFi8rnEESkclC4Vzbdu9u897Vrrf5MfLwty9SpE7RubWULSqhp\nUxv1WbfOatPMmAGdO8Mll8CqVcE/BBEJPYV7ZdWiBfztbzB7Nvz+u42tOAdnnFHqK5WOPBLuvdfG\n38eNg/fft5789derPo1IpFG4h4OjjoJrr4V582yY5txz4bnnSv1y8fFWeGzNGhg5EiZPtjH5sWNh\n27YgtltEQkbhHk4SE+3qpDPOsAW3//nPEo/D59awITz6KKxYYSsA/utfNk5///2wZ08Q2y0iFU7h\nHm6OOMKGZYYNgzvvhNGjbeHtMmjZ0uqX/fgj9OplPfhWraxHH8CCUSJSCSncw1G1avDSSzYm/8gj\nFvT795f5Zdu3hw8+gFmzoHFjuPpq6NjRxuZDVKVCREpJ4R6uoqLg3/+2MZQ33rCFVr/6Kigv3acP\nfPONXSy7fz8MHgynnGLj9K+/bguG/PlnUN5KRMqJwj2cOWfz4d97D9LS4OSTbSw+COvvOQcXXADL\nllnpmw0brErxpZfCiSdaHZuEBCuNM3asLo4SqWxUFTJS7NwJd99tSzPFx8PEiXDFFZbSQbJ7N/zy\ni104u2aNbcuX22zNgwdtvP6qq+DCC+1CWxEJvkCrQircI83ixTa/cd48KyP8wAN2YVQQQz6/P/6w\nE7KTJ9vMm1q17CrYc86xcfxmzWwUSUTKTuFelWVmwvPP25DNn3/aJPahQ21r06bc3tZ7G6ufPNlO\nA+zcaY/XrAlt21q9m6QkW1Skd287LywiJaNwFxuHf+steO01W54pM9Omv1x6qc2wady43N56926b\nWrlsWd4t+0rY+Hg4+2xbhOrMM+0DQESKp3CXvP74A6ZMsaD/9lsbFH//fZsaU4G2bYM5c2DaNKuR\ntm2bBfuAARb0Awda8ItIwRTuUriVK62Ewdq1Nt/xrLNC0owDB+xk7NtvW9j//rutMti3LwwZYluT\nJiFpmkilpXCXom3ZYt3lRYvsgqihQ0PanMxM+0Lx7rsW9CtX2uNdu9o8+5YtoU6dw7d69cq07KxI\n2FG4S/F27LDknD3bJrNff32oW3TIihUW9O+8YydpCxMVBUcfbT38xo3ttkkT+1Do27dcJwmJhITC\nXQKzZ4/NW/zgAytENnZsqFt0mG3b7IvGjh2Hb5s2QUpKzrZhgz0ONjHoppvgssusJI9IJAg03PWF\ntqqrUcMGva+4wlby2LYN/vEPiI4OdcsOSUiwLVBpaXau+OGHbQWqO+6wC3dvuMHK5ItUBeq5izl4\n0FbSfuopSE62xUE6dw51q8oke979ww/b8rSZmTbtsls3aNfOLrBq1QpiY0PdUpHAaVhGSs57W2h1\n9GhITYWbb7Yl/iJgTCMlBZ58MudkbXYp42rV4IQTLOyPO85O3B57rN02bKgra6XyUbhL6W3fbmMZ\nTz1lC7A++qjNS8y2Zw/89BMsWWIVw/r3L7/58hkZMH26dbODNKayd681e8kSWLrUbpctg/Xr85bG\nj4uD5s1tVk5srH0Q5L7t2BGuvBKOOSYozRIJiMJdym7ePPjrXy0BBwywojFLltiq2rlT0Dnr4d95\nZ9Fd3e3bYcwYm/P473/bilJF+eUXGD7c2hEVZSd+x4yx+gXlYP9+W1927Vrb1qyxJuzaZXPy9++3\n2wMH7ANi+XL7vQEDbBXEQYM0xCPlL9Bwx3sfkq1r165ewsD+/d7ff7/38fHeH3us9+ec4/348d7/\n97/er1jhfVqa98OGeQ/e9+/v/ZYtBb/OBx9436iR99HR3jdtavtffrn3qakF7//qq97XqWPb0097\nP2aM97Vr2+/16+f9jBneZ2aW33EHYO1a78eNs8MC7xs29P6OO7z//nvvN2zw/sCBkDZPIhQw3weQ\nsQp3KbvMTO+fesr7atUsuL/5Jue5rVu9v+wy+1Nr1877+fO937PHUjEmxvvERO9feSUnqNPScvbv\n2dMSNNv27fZBk52mHTt6/8UXZW//5597P3So98884/3OnSX+9QMHvH/vPe/POsv7qChrWvZWv773\nbdt637evvcXo0d7fd5/3L7zg/Ucfef/DD97/8UfIP6ckjCjcpeLNn+998+bex8Z6//DD3k+bZt3Z\nmBjr7e/bl3f/xYu9P/HEnF7/tGnet2xpCTlhQuFd3717vZ882fvjjrMPlHfeKV17N23yfvhwe/+a\nNe22Th3vb7jB2lYKKSnev/WW9088YYdw/fXen3ee97162RefI47IG/7ZW6NGtt+//uX97Nne79pV\nukOSyBfUcAf6Az8Dq4GxRex3PuCB5OJeU+Eeof780/uzz85JrU6drHtamIwM+yCoVcv2b9bM+zlz\nAn+v7t3tw+ONNwJv48GDNtSTkGAfROPGeb97t/dz59q3hurVc745vPSSPRdEO3d6v2aN91995f3b\nb3v/0EP2GXPccTn/bNHR3nfu7P2ll9pQz3/+4/3HH3u/fHnQmyNhJtBwL/aEqnMuGlgJnAGkAN8D\nQ733P+XbrzbwIVANuNF7X+TZUp1QjWCZmfD443bWcfTowM4y/vablSe+8sqSlYXcscMKn331lRWS\nv+KKovdfutTKLHz1lc3wefLJw2vcb90KL74I//mPzZusXRvOP98ude3Tp1wv8EpNtfPN33xjt6tX\n2zTOjIy8+x11VM6UzWOPzflAWgDuAAAMTUlEQVS5SRM7712zpl2fpvILkSdos2WccycBd3nv/5J1\n/w4A7/0/8+33EPApMAa4TeEuFWbXLqty+emnViNn5Mi8z2dkwOefW4G0KVOgbl2brXP55UWnn/fw\n5Ze2zNR//wvp6VbAZtgwm8XTvn35HleWgwetDv66dTab59dfbRZP9lKHKSnW1ILUrGlb7dq2IlbL\nlnm35s2t+Jpm+YSPYIb7BUB/7/01WfcvA0703t+Ya58uwP967893zs1C4S4Vbe9eW7z1gw8suG+5\nxZYcfOklq2H/++9Ww2D4cJgwwVb4Lok9e2wh8ldegY8/tg+M886DV1+1CfEhtG+fBf+aNfYhsGeP\nLZaSe9u+3fZZu9ZK++dXrZpdq1a7ds5tgwb2Wda4MTRqlPNzs2ZaIzeUKqy2jHMuCpgEjAhg3+uA\n6wCO0ZUfEkxxcTasM2wY3HqrDbesXm31gAcNsl76oEFQvXrpXr9GDbj4YttSU+31J0ywSe7vvVf6\ntDt40L5xNGhgaxHWqFHil6heHY4/3rZA7N6dE/S//mrBv3OnfTHJvk1Pt+fmzbNRqvwaNcp5z+yt\nTRsLfg0FVQ5lHpZxztUF1gBZK2bSEPgTGFxU7109dykXGRlWIWzJEgv6iy+GxMTyea9XX7Ux/s6d\n4aOPSv4+Gzfakodffmn3o6Ks2E2HDjnb6aeHfA3CvXvti8+GDbatXWtX+P78s5Vm3r49Z9/4eOjU\nyf5JsrcTTlDN/WAK5rBMDHZCtR+wATuheqn3flkh+89CwzJSVbz/vg0HHXssfPJJ4OvSzphhJ2h3\n7YIHH7RhoiVLbChp8WIbYwHrzb/1liVkJeS9fZH5+Wcr4bBoEfzwgx3C3r22T7Vq9s9z3HF5t5Yt\nrZeffwhp9277ItOuXfl9LoezoJYfcM4NBB4CooHJ3vt7nXP3YFNy3su37ywU7lKVzJplq30nJsJn\nn1mSFSYjA8aPt9r57drZCd78s3XAxkc+/9zqGuzeDc8+C5dcUm6HEGwZGRb4ixbZQumrV+dse/YE\n/joNG9o/U/Z29NF2jmHv3pzb7A+Ro4+24aJGjeznSF10XbVlRCrS/PlWQC02NiewExLyTptMSbHl\nDOfOtQLzDz9cfAJt2GBDS199ZSWZJ04s/XmDguzYYecLKmig3Hsb4lm92mb8REXlzOjJ3mrUsBGr\npUvzFnYryYcC2BBRo0b2Wdu6tY14ZW+NG4dvxU+Fu0hF++knK4a2cWPOY/HxNuRSv74l2v79Nn/+\n0ksDf90DB2yFrEmToHt3+/Bo1sye27DBPizmzLFt/374299gxAgbDynMypXw97/ba7VvD6NG2TmK\nUpzQrQiZmTbWv3WrnTuvXj3ntnp1+9D44w/7p8+9paTkfGPI7uGDHWZ2qefcW9Omlf+EsMJdJBQ2\nbbKhma1bbfvzz5yfq1eHBx4IfFpLfm+/baEdG2uzdObNs+4v2JVLPXva2c3vv7c6xHfcYReF5e7p\n//abVfB84QVLxxEj7MPhxx/tA+i662z5qiZNyvgPUblkZlrQr1pln2srV9pn8dKleT+L69Sxuf8N\nGtiWmJjz85FH2sVj2bd16oTmg0DhLhKJVq2yHva6dXDyydC7t22dOtmUFO/tZO3dd9tlrk2aWMif\nfbb1/J94wl5n5Eh7/Kij7Hdmz7ZhonfftcS64AIbDjrpJBv4LsrBg5aWW7ZY97ckayLmt3mznZNI\nT7cPq5NOsllDhU23OXDA5mx6b+MtpbBtmw37ZA8DrV9vJ4m3bLHb3LOBcqteHXrWW0Gf2guJvvA8\n/jIkjq5dAxvu8b70HwwKd5GqzHubP3/33dbDB0udESNsfn5h15msWwePPWYncNPS7LEWLXKCtmdP\n6/EvWGDb/Pl21nTnzpzXaN7c5kBmz4ns2tUGv4tr72uv2epf6en2LeL33+25mjVtOKpnT+tCr1mT\nM9aybl1ObYZRo+C++4I+tHTggAX95s22bdoEUd99Q4eP7qft6neJwrOcE7ia51hzZE8GDICBA+G0\n0+yDIfubwsqVdpJ55UpbJmHcuNK1R+EuIhaaX3xhM28uvzzwKZX79tmcxnnzcrbssM1Wo4YFeNeu\nth15pJ39/OEH21atyqmLcMopcNVV9o2gVq28r5OSYvV+PvzQPkCee87a+dtv8PXX9t5ff20fIhkZ\nNh7SqlXeeZULF9qKYUlJ9iHRoUPhx7Zwob1HgwbQty/06BHYSWrv7erk+++3axMSEuyaik6dODj6\nFqI2rGdGq5u4ZvM/2LC91mG/Hh9vI3KtW1upotyLm5WEwl1Egsd7C9t586wr26VL8VcnpafbhPdZ\ns2yMf/Vqm5kzdChcfbUtxP7ss7a61oED8I9/wE03FV6YLXsSfP36BY9pzJhh30z+/NN68DffnDNG\nkh3MEyfah12NGvYBlplp30R69rSgP+00G6rasuXw7aOP7NxE48Z2FfQ11+RcmZyebsNcjz+Ob9GC\nZTc/w4d7+3HUURbmrVsX3uyS0kpMIlJ5ZGZ6/+WXtvpWjRpW17hBA7vt29f71auD8z6bN3s/ZIi9\n7umn22Ivzz/vfVKSPda4sfcPPGALv2zbZqusjB5tC78UVGg/e4uJ8b5DB3ut/OsS5DZ7tvetWtnv\nXH21LcuVkRGcY8tCsEr+lhf13EWqqLQ0ePNNu7r37LPtQq1gTjvxHp55xqaE7t5tj3XoALfdZieJ\nC5siumWLnVjeudOmyeTeSnItwJ49cNdd9i0hM9OqkJ5yin0z6NvX2lKGSfYalhGRqm3lSgv5M86w\nraLnLW7aBDNn2jDQzJk2LAVWY/nOO21opxQU7iIilUlKioX8zJlw5pmlLiehcBcRiUCBhnuYVlcQ\nEZGiKNxFRCKQwl1EJAIp3EVEIpDCXUQkAincRUQikMJdRCQCKdxFRCJQyC5ics6lAr+W8tcTgS1B\nbE44qarHruOuWnTchWvmvW9Q3AuFLNzLwjk3P5ArtCJRVT12HXfVouMuOw3LiIhEIIW7iEgECtdw\nfzrUDQihqnrsOu6qRcddRmE55i4iIkUL1567iIgUIezC3TnX3zn3s3NutXNubKjbU16cc5Odc5ud\nc0tzPVbPOfepc25V1m1CKNtYHpxzTZ1zM51zPznnljnnbs56PKKP3TkX55z7zjn3Y9Zx3531eAvn\n3LdZf+9vOucKWSMuvDnnop1zPzjnPsi6H/HH7Zxb55xb4pxb5Jybn/VY0P7OwyrcnXPRwOPAAKAt\nMNQ51za0rSo3LwD98z02Fvjce98K+DzrfqTJAG713rcFegA3ZP03jvRj3wec5r3vCHQC+jvnegD3\nAw96748DtgFXh7CN5elmYHmu+1XluPt67zvlmv4YtL/zsAp3oDuw2nu/1nu/H3gDGBLiNpUL7/1s\n4M98Dw8BXsz6+UXgnAptVAXw3v/uvV+Y9XM69j98YyL82LMWtt+ZdTc2a/PAacDUrMcj7rgBnHNN\ngEHAs1n3HVXguAsRtL/zcAv3xsD6XPdTsh6rKo7y3v+e9fMfwFGhbEx5c841BzoD31IFjj1raGIR\nsBn4FFgDbPfeZ2TtEql/7w8B/wNkZt2vT9U4bg984pxb4Jy7LuuxoP2dx5S1dRIa3nvvnIvYqU7O\nuSOAt4DR3vsdLtfK9ZF67N77g0An51w8MA04IcRNKnfOubOAzd77Bc65U0Pdngp2svd+g3PuSOBT\n59yK3E+W9e883HruG4Cmue43yXqsqtjknDsaIOt2c4jbUy6cc7FYsL/qvX876+EqcewA3vvtwEzg\nJCDeOZfdCYvEv/dewGDn3DpsmPU04GEi/7jx3m/Iut2MfZh3J4h/5+EW7t8DrbLOpFcDLgHeC3Gb\nKtJ7wBVZP18BvBvCtpSLrPHW54Dl3vtJuZ6K6GN3zjXI6rHjnKsBnIGdb5gJXJC1W8Qdt/f+Du99\nE+99c+z/5y+898OI8ON2ztVyztXO/hk4E1hKEP/Ow+4iJufcQGyMLhqY7L2/N8RNKhfOudeBU7Eq\ncZuACcA7wBTgGKyi5kXe+/wnXcOac+5kYA6whJwx2DuxcfeIPXbnXAfsBFo01uma4r2/xznXEuvR\n1gN+AIZ77/eFrqXlJ2tY5jbv/VmRftxZxzct624M8Jr3/l7nXH2C9HceduEuIiLFC7dhGRERCYDC\nXUQkAincRUQikMJdRCQCKdxFRCKQwl1EJAIp3EVEIpDCXUQkAv1/01LXhR0eIzoAAAAASUVORK5C\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7c14bb02b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD8CAYAAACb4nSYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7c0c044668>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(len(global_train_loss)), global_train_loss, 'b', label = 'training loss')\n",
    "plt.plot(range(len(global_valid_loss)), global_valid_loss, 'r', label = 'validation loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(range(len(global_train_acc)), global_train_acc, 'b', label = 'training accuracy')\n",
    "plt.plot(range(len(global_valid_acc)), global_valid_acc, 'r', label = 'validation accuracy')\n",
    "plt.legend(loc = 4)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {
    "6b1438b3075f49289cfcf03a4fce2ccb": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    },
    "ab7848b490e5454e9a42f439a6ef6b31": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    },
    "e0e3b0d66b1e47c4ade6c276bacc5c55": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
