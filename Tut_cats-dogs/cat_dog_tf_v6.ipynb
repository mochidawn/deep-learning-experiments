{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multi-gpu version\n",
    "\n",
    "### -> make model become module`\n",
    "# transfer learning branch\n",
    "# attention model branch\n",
    "# basic model branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Apr 20 13:52:36 2018       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 384.81                 Driver Version: 384.81                    |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce GTX 108...  Off  | 00000000:04:00.0 Off |                  N/A |\n",
      "| 23%   31C    P8    15W / 250W |      0MiB / 11172MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  GeForce GTX 108...  Off  | 00000000:06:00.0 Off |                  N/A |\n",
      "| 23%   30C    P8    15W / 250W |      0MiB / 11172MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  GeForce GTX 108...  Off  | 00000000:07:00.0 Off |                  N/A |\n",
      "| 23%   29C    P8    16W / 250W |  10623MiB / 11172MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  GeForce GTX 108...  Off  | 00000000:08:00.0 Off |                  N/A |\n",
      "| 23%   28C    P8    15W / 250W |  10623MiB / 11172MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   4  GeForce GTX 108...  Off  | 00000000:0C:00.0 Off |                  N/A |\n",
      "| 23%   31C    P8     8W / 250W |      0MiB / 11172MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   5  GeForce GTX 108...  Off  | 00000000:0D:00.0 Off |                  N/A |\n",
      "| 23%   32C    P8    16W / 250W |      0MiB / 11172MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   6  GeForce GTX 108...  Off  | 00000000:0E:00.0 Off |                  N/A |\n",
      "| 23%   32C    P8    15W / 250W |    296MiB / 11172MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   7  GeForce GTX 108...  Off  | 00000000:0F:00.0 Off |                  N/A |\n",
      "| 23%   29C    P8     8W / 250W |  11010MiB / 11172MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|    2     12701      C   /usr/bin/python3                           10613MiB |\n",
      "|    3     12701      C   /usr/bin/python3                           10613MiB |\n",
      "|    6     13373      C   /usr/bin/python3                             143MiB |\n",
      "|    6     32437      C   /usr/bin/python3                             143MiB |\n",
      "|    7     10594      C   /usr/bin/python3                           11000MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(batch_size=48, do_augment=True, epochs=50, gpu_id=5, image_dir='/home/seanyu/datasets/cat_dog/dataset/', image_size=(120, 120, 3), is_training=1, lr=0.0001, n_classes=2, save_dir='./result', train_ratio=0.9, use_model_ckpt=None)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "#\n",
    "import os\n",
    "import glob\n",
    "import re\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import subprocess\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from time import sleep\n",
    "from tqdm import tqdm # if use notebook\n",
    "\n",
    "from threading import Thread, Event\n",
    "import queue\n",
    "\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import imgaug as ia\n",
    "from imgaug import augmenters as iaa\n",
    "\n",
    "import random\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--gpu_id', default=5)\n",
    "parser.add_argument('--image_dir', default=\"/home/seanyu/datasets/cat_dog/dataset/\")\n",
    "parser.add_argument('--save_dir', default='./result')\n",
    "parser.add_argument('--is_training', default=1, type=int)\n",
    "parser.add_argument('--batch_size', default=48, type=int)\n",
    "parser.add_argument('--do_augment', default=True, type = bool)\n",
    "parser.add_argument('--epochs', default=50, type=int)\n",
    "parser.add_argument('--lr', default=0.0001, type=float)\n",
    "parser.add_argument('--image_size', default=(120,120,3), type = int)\n",
    "parser.add_argument('--n_classes', default=2, type = int)\n",
    "parser.add_argument('--train_ratio', default=0.9, type = float)\n",
    "parser.add_argument('--use_model_ckpt', default = None, type = str)\n",
    "FLAGS = parser.parse_args([])\n",
    "print(FLAGS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = str(FLAGS.gpu_id)\n",
    "import tensorflow as tf\n",
    "\n",
    "if not os.path.exists(FLAGS.save_dir):\n",
    "    os.makedirs(FLAGS.save_dir)\n",
    "\n",
    "model_graph_name = FLAGS.save_dir + '/model'\n",
    "    \n",
    "graphs_dir = FLAGS.save_dir + '/graphs'\n",
    "if not os.path.exists(graphs_dir):\n",
    "    os.makedirs(graphs_dir)\n",
    "\n",
    "\"\"\"  Get data \"\"\"\n",
    "d_train = FLAGS.image_dir + '/train/'\n",
    "d_test = FLAGS.image_dir + '/test1/'\n",
    "\n",
    "image_train_list = glob.glob(d_train + '*.jpg')\n",
    "image_test_list = glob.glob(d_test + '*.jpg')\n",
    "\n",
    "df_train = pd.DataFrame({'img_path': image_train_list})\n",
    "df_test = pd.DataFrame({'img_path': image_test_list})\n",
    "\n",
    "df_train['cate'] = df_train.img_path.apply(os.path.basename)\n",
    "df_train['cate'] = [i.split(\".\")[0] for i in list(df_train.cate)]\n",
    "df_train.cate = df_train.cate.replace({'dog': 0, 'cat': 1})\n",
    "\n",
    "nb_epoch = FLAGS.epochs\n",
    "\n",
    "df_train_0, df_val_0 = train_test_split(df_train[df_train['cate'] == 0], test_size = 1-FLAGS.train_ratio)\n",
    "df_train_1, df_val_1 = train_test_split(df_train[df_train['cate'] == 1], test_size = 1-FLAGS.train_ratio)\n",
    "\n",
    "df_val = pd.concat((df_val_0, df_val_1)).reset_index(drop = True)\n",
    "\n",
    "del df_val_0, df_val_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.contrib.slim as slim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def enqueue(queue, stop, gen_func):\n",
    "    gen = gen_func()\n",
    "    while True:\n",
    "        if stop.is_set():\n",
    "            return\n",
    "        queue.put(next(gen))\n",
    "\n",
    "class create_data_generator():\n",
    "    def __init__(self,\n",
    "                 df,\n",
    "                 open_image_handler, \n",
    "                 data_frame_handler = None,\n",
    "                 nd_inputs_preprocessing_handler = None,\n",
    "                 batch_size = 32,\n",
    "                 n_classes = 2,\n",
    "                 aug_params = None):\n",
    "        \n",
    "        self.f_readImg = open_image_handler  # how to open image\n",
    "        self.f_dataproc = data_frame_handler # how to proc original data\n",
    "        self.f_inputs_preproc = nd_inputs_preprocessing_handler # how to do image preprocessing\n",
    "        self.bz = batch_size\n",
    "        self.n_classes = n_classes\n",
    "        self.aug = aug_params\n",
    "        \n",
    "        # run functions at the begin\n",
    "        # self.df should become list of dataframe anyway\n",
    "        # if not, do the data_preproc. if yes, pass it\n",
    "        if data_frame_handler:\n",
    "            self.df = self.f_dataproc(df)\n",
    "        else:\n",
    "            self.df = df\n",
    "       \n",
    "    def get_train_data(self):\n",
    "        while True:\n",
    "            idxs = self.train_idx_queue.get()\n",
    "\n",
    "            select_list = []\n",
    "\n",
    "            for df, idx in zip(self.df, idxs):\n",
    "                select_list.append(df.iloc[idx])\n",
    "            select_list = pd.concat(select_list)\n",
    "            \n",
    "            x_ = np.array([self.f_readImg(iid) for iid in select_list.img_path], dtype=np.float32)\n",
    "            x_ = x_.astype(np.float32)\n",
    "            \"\"\" do preprocessing here\"\"\"\n",
    "            if self.f_inputs_preproc:\n",
    "                x_ = self.f_inputs_preproc(x_)\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "            \"\"\" Y out \"\"\"\n",
    "            y_ = np.array(select_list['cate'])\n",
    "            y_ = tf.keras.utils.to_categorical(y_, self.n_classes)\n",
    "\n",
    "            yield x_, y_\n",
    "        \n",
    "    def get_evaluate_data(self, target_df):\n",
    "        \n",
    "        x_ = np.array([cv_load_and_resize(i, is_training = False) for i in target_df.img_path], dtype=np.float32) # don't do augmentation!\n",
    "    \n",
    "        \"\"\" do preprocessing here\"\"\"\n",
    "        if self.f_inputs_preproc:\n",
    "            x_ = self.f_inputs_preproc(x_)\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "        \"\"\" Y out \"\"\"\n",
    "        y_ = np.array(target_df['cate'])\n",
    "        y_ = tf.keras.utils.to_categorical(y_, num_classes=self.n_classes)\n",
    "        \n",
    "        return x_, y_\n",
    "    \n",
    "    def _get_train_idx(self):\n",
    "        \"\"\" Description \n",
    "        Get training data index for each data frame in the data list\n",
    "        # note1: self.df should be list of data frame with different categories\n",
    "        # note2: if there is only 1 class (or for regression problem, should still be embraced [this_df] )\n",
    "        \"\"\"\n",
    "        len_list = [len(df) for df in self.df]\n",
    "        \n",
    "        bz_t = self.bz//len(len_list)\n",
    "        batch_num = [x//bz_t for x in len_list]\n",
    "\n",
    "        batch_nth = [0] * len(len_list)\n",
    "\n",
    "        select = [list(range(x)) for x in len_list]\n",
    "\n",
    "        for s in select:\n",
    "            random.shuffle(s)\n",
    "\n",
    "        while True:\n",
    "            idxs = []\n",
    "            for i in range(len(len_list)):\n",
    "                if batch_nth[i] >= batch_num[i]:\n",
    "                    batch_nth[i] = 0\n",
    "                    random.shuffle(select[i])\n",
    "                idx = select[i][batch_nth[i]*bz_t:(batch_nth[i]+1)*bz_t]\n",
    "                batch_nth[i] += 1\n",
    "                idxs.append(idx)\n",
    "\n",
    "            yield idxs\n",
    "    \n",
    "\n",
    "        \n",
    "    def start_train_threads(self, jobs = 1):\n",
    "        \n",
    "        self.train_queue = queue.Queue(maxsize = 10)\n",
    "        self.train_idx_queue =queue.Queue(maxsize = 100)\n",
    "        \n",
    "        ### for stop threads after training ###\n",
    "        self.events=[]\n",
    "\n",
    "        ### enqueue train index ###\n",
    "        event = Event()\n",
    "        thread = Thread(target = enqueue, \n",
    "                        args = (self.train_idx_queue, \n",
    "                                event, \n",
    "                                self._get_train_idx))\n",
    "        thread.start()\n",
    "        self.events.append(event)\n",
    "\n",
    "        ### enqueue train batch ###\n",
    "        for i in range(jobs):\n",
    "            event = Event()\n",
    "            thread = Thread(target = enqueue,args = (self.train_queue, \n",
    "                                                     event, \n",
    "                                                     self.get_train_data))\n",
    "            thread.start()\n",
    "            self.events.append(event)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping():\n",
    "    def __init__(self, patience, min_delta = 0.0001):\n",
    "        # validation loss should at least be less than current min_loss - min_delta\n",
    "        self.min_delta = min_delta \n",
    "        self.patience = patience\n",
    "        self.epoch_count = 0\n",
    "        self.min_loss = None\n",
    "        self.stop = False\n",
    "        \n",
    "    def on_epoch_end(self, val_loss, *args, **kwargs):\n",
    "        if self.min_loss is None or val_loss < self.min_loss - self.min_delta:\n",
    "            self.min_loss = val_loss\n",
    "            self.epoch_count = 0\n",
    "        else:\n",
    "            self.epoch_count += 1\n",
    "            \n",
    "        # if cumulative counts is larger than our patience, set the stop signal to True\n",
    "        if self.epoch_count >= self.patience:\n",
    "            self.stop = True\n",
    "        \n",
    "class Model_checkpoint():\n",
    "    def __init__(self, model_name, save_best_only = True):\n",
    "        self.min_loss = None\n",
    "        self.model_name = model_name\n",
    "        self.save_best_only = save_best_only\n",
    "        \n",
    "    def on_epoch_end(self, val_loss, nth_epoch, saver, sess, *args, **kwargs):\n",
    "        if self.min_loss is None or val_loss < self.min_loss:\n",
    "            self.min_loss = val_loss\n",
    "            saver.save(sess, \n",
    "                       self.model_name + '.ckpt')\n",
    "        if not self.save_best_only:\n",
    "            saver.save(sess, \n",
    "                       self.model_name + '_' + str(nth_epoch) + '.ckpt',\n",
    "                       global_step=nth_epoch)\n",
    "        \n",
    "class ReduceLROnPlateau():\n",
    "    def __init__(self, lr, factor, patience, min_lr = 1e-10):\n",
    "        self.lr = lr\n",
    "        self.factor = factor\n",
    "        self.patience = patience\n",
    "        self.min_lr = min_lr\n",
    "        self.min_loss = None\n",
    "        self.epoch_count = 0\n",
    "    \n",
    "    def on_epoch_end(self, val_loss, *args, **kwargs):\n",
    "        if self.min_loss is None or val_loss < self.min_loss:\n",
    "            epoch_count = 0\n",
    "            self.min_loss = val_loss\n",
    "        else:\n",
    "            self.epoch_count += 1\n",
    "        \n",
    "        if self.epoch_count == self.patience:\n",
    "            self.lr *= self.factor\n",
    "            self.epoch_count = 0\n",
    "            \n",
    "            if self.lr <= self.min_lr:\n",
    "                self.lr = self.min_lr\n",
    "                \n",
    "class Run_collected_functions():\n",
    "    def __init__(self, callback_dicts):\n",
    "        self.on_session_begin = callback_dicts['on_session_begin']\n",
    "        self.on_session_end = callback_dicts['on_session_end']\n",
    "        self.on_batch_begin = callback_dicts['on_batch_begin']\n",
    "        self.on_batch_end = callback_dicts['on_batch_end']\n",
    "        self.on_epoch_begin = callback_dicts['on_epoch_begin']\n",
    "        self.on_epoch_end = callback_dicts['on_epoch_end']\n",
    "        \n",
    "    def run_on_epoch_end(self, val_loss, nth_epoch = None, sess = None, saver = None):\n",
    "        for func in self.on_epoch_end:\n",
    "            getattr(func, 'on_epoch_end')(val_loss = val_loss,\n",
    "                                          nth_epoch = nth_epoch,\n",
    "                                          sess = sess,\n",
    "                                          saver = saver)\n",
    "        \n",
    "    def run_on_session_end(self, *args, **kwargs):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sometimes = lambda aug: iaa.Sometimes(0.5, aug)\n",
    "\n",
    "seq = iaa.Sequential([\n",
    "    iaa.Crop(px=(0, 16)), # crop images from each side by 0 to 16px (randomly chosen)\n",
    "    iaa.Fliplr(0.5), # horizontally flip 50% of the images\n",
    "    sometimes(iaa.Affine(\n",
    "            scale = (0.8,1.2),\n",
    "            translate_percent = (-0.2, 0.2),\n",
    "            rotate = (-30, 30),\n",
    "            order = [0, 1],\n",
    "            #cval = (0,255),\n",
    "            mode = 'wrap'\n",
    "            ))\n",
    "])\n",
    "\n",
    "def cv_load_and_resize(x, is_training = True):\n",
    "    im_w, im_h, im_c = FLAGS.image_size\n",
    "    im = cv2.imread(x)\n",
    "    im = cv2.resize(im, (im_w, im_h))\n",
    "    if FLAGS.do_augment and is_training:\n",
    "        im = seq.augment_image(im)\n",
    "    return im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_gen = create_data_generator(df=[df_train_0, df_train_1],\n",
    "                                 aug_params=seq,\n",
    "                                 batch_size=FLAGS.batch_size, \n",
    "                                 open_image_handler=cv_load_and_resize)\n",
    "data_gen.start_train_threads(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2500, 120, 120, 3)\n"
     ]
    }
   ],
   "source": [
    "x_val, y_val = data_gen.get_evaluate_data(df_val)\n",
    "print(x_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "im_w, im_h, im_c = FLAGS.image_size\n",
    "drp_holder = tf.placeholder(tf.float32)\n",
    "\n",
    "a_in = tf.keras.layers.Input(shape = (im_w, im_h, im_c))\n",
    "x = tf.keras.layers.Conv2D(kernel_size=(3,3), filters=32, activation=tf.nn.selu)(a_in)\n",
    "x = tf.keras.layers.MaxPooling2D(pool_size=(2,2))(x)\n",
    "\n",
    "x = tf.keras.layers.Conv2D(kernel_size=(3,3), filters=32, activation=tf.nn.selu)(x)\n",
    "x = tf.keras.layers.MaxPooling2D(pool_size=(2,2))(x)\n",
    "\n",
    "x = tf.keras.layers.Conv2D(kernel_size=(3,3), filters=64, activation=tf.nn.selu)(x)\n",
    "x = tf.keras.layers.MaxPooling2D(pool_size=(2,2))(x)\n",
    "\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "\n",
    "x = tf.keras.layers.Dense(units=64, activation=tf.nn.selu)(x)\n",
    "x = tf.keras.layers.Dropout(drp_holder)(x)\n",
    "\n",
    "x = tf.keras.layers.Dense(units=32, activation=tf.nn.selu)(x)\n",
    "x = tf.keras.layers.Dropout(drp_holder)(x)\n",
    "\n",
    "out = tf.keras.layers.Dense(units=FLAGS.n_classes, activation='linear')(x) # softmax will be at loss part\n",
    "\n",
    "y_holder = tf.placeholder(tf.float32, shape=[None, FLAGS.n_classes])\n",
    "total_loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_holder, logits=out))\n",
    "\n",
    "\n",
    "optim = tf.train.AdamOptimizer(learning_rate=FLAGS.lr)\n",
    "optim_op = optim.minimize(total_loss)\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(tf.nn.softmax(out), 1), \n",
    "                              tf.argmax(y_holder, 1))\n",
    "accuracy_op = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Training loss/acc: 1.14/0.53: 100%|██████████| 521/521 [00:30<00:00, 17.12batch/s]\n",
      "Epoch: 1, Validation loss/acc: 0.65/0.64: 100%|██████████| 53/53 [00:00<00:00, 77.44batch/s]\n",
      "Epoch: 2, Training loss/acc: 0.79/0.58: 100%|██████████| 521/521 [00:29<00:00, 17.78batch/s]\n",
      "Epoch: 2, Validation loss/acc: 0.62/0.67: 100%|██████████| 53/53 [00:00<00:00, 116.28batch/s]\n",
      "Epoch: 3, Training loss/acc: 0.70/0.61: 100%|██████████| 521/521 [00:29<00:00, 17.90batch/s]\n",
      "Epoch: 3, Validation loss/acc: 0.61/0.67: 100%|██████████| 53/53 [00:00<00:00, 106.70batch/s]\n",
      "Epoch: 4, Training loss/acc: 0.66/0.63: 100%|██████████| 521/521 [00:27<00:00, 19.22batch/s]\n",
      "Epoch: 4, Validation loss/acc: 0.57/0.71: 100%|██████████| 53/53 [00:00<00:00, 89.59batch/s]\n",
      "Epoch: 5, Training loss/acc: 0.64/0.65: 100%|██████████| 521/521 [00:27<00:00, 18.90batch/s]\n",
      "Epoch: 5, Validation loss/acc: 0.57/0.71: 100%|██████████| 53/53 [00:00<00:00, 107.22batch/s]\n",
      "Epoch: 6, Training loss/acc: 0.61/0.67: 100%|██████████| 521/521 [00:26<00:00, 19.62batch/s]\n",
      "Epoch: 6, Validation loss/acc: 0.57/0.71: 100%|██████████| 53/53 [00:00<00:00, 117.39batch/s]\n",
      "Epoch: 7, Training loss/acc: 0.61/0.68: 100%|██████████| 521/521 [00:26<00:00, 19.75batch/s]\n",
      "Epoch: 7, Validation loss/acc: 0.56/0.73: 100%|██████████| 53/53 [00:00<00:00, 112.68batch/s]\n",
      "Epoch: 8, Training loss/acc: 0.58/0.69: 100%|██████████| 521/521 [00:24<00:00, 21.26batch/s]\n",
      "Epoch: 8, Validation loss/acc: 0.57/0.70: 100%|██████████| 53/53 [00:00<00:00, 123.61batch/s]\n",
      "Epoch: 9, Training loss/acc: 0.58/0.70: 100%|██████████| 521/521 [00:26<00:00, 20.03batch/s]\n",
      "Epoch: 9, Validation loss/acc: 0.53/0.75: 100%|██████████| 53/53 [00:00<00:00, 124.34batch/s]\n",
      "Epoch: 10, Training loss/acc: 0.57/0.71: 100%|██████████| 521/521 [00:27<00:00, 18.80batch/s]\n",
      "Epoch: 10, Validation loss/acc: 0.54/0.73: 100%|██████████| 53/53 [00:00<00:00, 124.01batch/s]\n",
      "Epoch: 11, Training loss/acc: 0.56/0.72: 100%|██████████| 521/521 [00:27<00:00, 18.87batch/s]\n",
      "Epoch: 11, Validation loss/acc: 0.51/0.75: 100%|██████████| 53/53 [00:00<00:00, 118.36batch/s]\n",
      "Epoch: 12, Training loss/acc: 0.55/0.72: 100%|██████████| 521/521 [00:28<00:00, 18.58batch/s]\n",
      "Epoch: 12, Validation loss/acc: 0.52/0.75: 100%|██████████| 53/53 [00:00<00:00, 112.92batch/s]\n",
      "Epoch: 13, Training loss/acc: 0.54/0.73: 100%|██████████| 521/521 [00:26<00:00, 19.35batch/s]\n",
      "Epoch: 13, Validation loss/acc: 0.53/0.74: 100%|██████████| 53/53 [00:00<00:00, 122.73batch/s]\n",
      "Epoch: 14, Training loss/acc: 0.53/0.73: 100%|██████████| 521/521 [00:28<00:00, 18.17batch/s]\n",
      "Epoch: 14, Validation loss/acc: 0.51/0.77: 100%|██████████| 53/53 [00:00<00:00, 123.59batch/s]\n",
      "Epoch: 15, Training loss/acc: 0.53/0.74: 100%|██████████| 521/521 [00:28<00:00, 18.17batch/s]\n",
      "Epoch: 15, Validation loss/acc: 0.51/0.75: 100%|██████████| 53/53 [00:00<00:00, 118.47batch/s]\n",
      "Epoch: 16, Training loss/acc: 0.51/0.75: 100%|██████████| 521/521 [00:28<00:00, 18.47batch/s]\n",
      "Epoch: 16, Validation loss/acc: 0.52/0.74: 100%|██████████| 53/53 [00:00<00:00, 107.20batch/s]\n",
      "Epoch: 17, Training loss/acc: 0.52/0.75: 100%|██████████| 521/521 [00:28<00:00, 17.99batch/s]\n",
      "Epoch: 17, Validation loss/acc: 0.50/0.77: 100%|██████████| 53/53 [00:00<00:00, 104.63batch/s]\n",
      "Epoch: 18, Training loss/acc: 0.51/0.76: 100%|██████████| 521/521 [00:29<00:00, 17.70batch/s]\n",
      "Epoch: 18, Validation loss/acc: 0.47/0.78: 100%|██████████| 53/53 [00:00<00:00, 111.51batch/s]\n",
      "Epoch: 19, Training loss/acc: 0.50/0.76: 100%|██████████| 521/521 [00:30<00:00, 16.95batch/s]\n",
      "Epoch: 19, Validation loss/acc: 0.48/0.78: 100%|██████████| 53/53 [00:00<00:00, 107.15batch/s]\n",
      "Epoch: 20, Training loss/acc: 0.49/0.77: 100%|██████████| 521/521 [00:29<00:00, 17.75batch/s]\n",
      "Epoch: 20, Validation loss/acc: 0.51/0.76: 100%|██████████| 53/53 [00:00<00:00, 107.82batch/s]\n",
      "Epoch: 21, Training loss/acc: 0.49/0.77: 100%|██████████| 521/521 [00:28<00:00, 18.45batch/s]\n",
      "Epoch: 21, Validation loss/acc: 0.47/0.78: 100%|██████████| 53/53 [00:00<00:00, 95.57batch/s]\n",
      "Epoch: 22, Training loss/acc: 0.48/0.77: 100%|██████████| 521/521 [00:28<00:00, 18.25batch/s]\n",
      "Epoch: 22, Validation loss/acc: 0.46/0.78: 100%|██████████| 53/53 [00:00<00:00, 112.07batch/s]\n",
      "Epoch: 23, Training loss/acc: 0.47/0.78: 100%|██████████| 521/521 [00:28<00:00, 18.60batch/s]\n",
      "Epoch: 23, Validation loss/acc: 0.46/0.78: 100%|██████████| 53/53 [00:00<00:00, 117.91batch/s]\n",
      "Epoch: 24, Training loss/acc: 0.47/0.78: 100%|██████████| 521/521 [00:29<00:00, 17.96batch/s]\n",
      "Epoch: 24, Validation loss/acc: 0.45/0.79: 100%|██████████| 53/53 [00:00<00:00, 117.62batch/s]\n",
      "Epoch: 25, Training loss/acc: 0.46/0.79: 100%|██████████| 521/521 [00:28<00:00, 18.32batch/s]\n",
      "Epoch: 25, Validation loss/acc: 0.47/0.79: 100%|██████████| 53/53 [00:00<00:00, 99.71batch/s]\n",
      "Epoch: 26, Training loss/acc: 0.46/0.78: 100%|██████████| 521/521 [00:28<00:00, 18.28batch/s]\n",
      "Epoch: 26, Validation loss/acc: 0.48/0.77: 100%|██████████| 53/53 [00:00<00:00, 116.73batch/s]\n",
      "Epoch: 27, Training loss/acc: 0.46/0.79: 100%|██████████| 521/521 [00:28<00:00, 18.28batch/s]\n",
      "Epoch: 27, Validation loss/acc: 0.43/0.81: 100%|██████████| 53/53 [00:00<00:00, 120.44batch/s]\n",
      "Epoch: 28, Training loss/acc: 0.45/0.79: 100%|██████████| 521/521 [00:28<00:00, 18.25batch/s]\n",
      "Epoch: 28, Validation loss/acc: 0.42/0.80: 100%|██████████| 53/53 [00:00<00:00, 115.19batch/s]\n",
      "Epoch: 29, Training loss/acc: 0.45/0.79: 100%|██████████| 521/521 [00:27<00:00, 18.85batch/s]\n",
      "Epoch: 29, Validation loss/acc: 0.41/0.81: 100%|██████████| 53/53 [00:00<00:00, 97.38batch/s]\n",
      "Epoch: 30, Training loss/acc: 0.44/0.80: 100%|██████████| 521/521 [00:27<00:00, 19.17batch/s]\n",
      "Epoch: 30, Validation loss/acc: 0.42/0.81: 100%|██████████| 53/53 [00:00<00:00, 112.17batch/s]\n",
      "Epoch: 31, Training loss/acc: 0.44/0.80: 100%|██████████| 521/521 [00:26<00:00, 19.93batch/s]\n",
      "Epoch: 31, Validation loss/acc: 0.41/0.81: 100%|██████████| 53/53 [00:00<00:00, 96.02batch/s]\n",
      "Epoch: 32, Training loss/acc: 0.43/0.80: 100%|██████████| 521/521 [00:26<00:00, 19.32batch/s]\n",
      "Epoch: 32, Validation loss/acc: 0.44/0.81: 100%|██████████| 53/53 [00:00<00:00, 116.19batch/s]\n",
      "Epoch: 33, Training loss/acc: 0.43/0.80: 100%|██████████| 521/521 [00:26<00:00, 19.97batch/s]\n",
      "Epoch: 33, Validation loss/acc: 0.41/0.82: 100%|██████████| 53/53 [00:00<00:00, 95.18batch/s]\n",
      "Epoch: 34, Training loss/acc: 0.43/0.81: 100%|██████████| 521/521 [00:27<00:00, 19.10batch/s]\n",
      "Epoch: 34, Validation loss/acc: 0.39/0.82: 100%|██████████| 53/53 [00:00<00:00, 115.92batch/s]\n",
      "Epoch: 35, Training loss/acc: 0.42/0.81: 100%|██████████| 521/521 [00:28<00:00, 18.16batch/s]\n",
      "Epoch: 35, Validation loss/acc: 0.40/0.82: 100%|██████████| 53/53 [00:00<00:00, 114.85batch/s]\n",
      "Epoch: 36, Training loss/acc: 0.42/0.81: 100%|██████████| 521/521 [00:28<00:00, 18.17batch/s]\n",
      "Epoch: 36, Validation loss/acc: 0.39/0.82: 100%|██████████| 53/53 [00:00<00:00, 116.71batch/s]\n",
      "Epoch: 37, Training loss/acc: 0.41/0.81: 100%|██████████| 521/521 [00:27<00:00, 18.91batch/s]\n",
      "Epoch: 37, Validation loss/acc: 0.43/0.79: 100%|██████████| 53/53 [00:00<00:00, 113.87batch/s]\n",
      "Epoch: 38, Training loss/acc: 0.41/0.81: 100%|██████████| 521/521 [00:29<00:00, 17.54batch/s]\n",
      "Epoch: 38, Validation loss/acc: 0.38/0.83: 100%|██████████| 53/53 [00:00<00:00, 108.63batch/s]\n",
      "Epoch: 39, Training loss/acc: 0.41/0.82: 100%|██████████| 521/521 [00:28<00:00, 18.16batch/s]\n",
      "Epoch: 39, Validation loss/acc: 0.38/0.83: 100%|██████████| 53/53 [00:00<00:00, 113.26batch/s]\n",
      "Epoch: 40, Training loss/acc: 0.41/0.82: 100%|██████████| 521/521 [00:28<00:00, 18.52batch/s]\n",
      "Epoch: 40, Validation loss/acc: 0.39/0.82: 100%|██████████| 53/53 [00:00<00:00, 116.45batch/s]\n",
      "Epoch: 41, Training loss/acc: 0.40/0.82: 100%|██████████| 521/521 [00:27<00:00, 18.86batch/s]\n",
      "Epoch: 41, Validation loss/acc: 0.42/0.82: 100%|██████████| 53/53 [00:00<00:00, 109.66batch/s]\n",
      "Epoch: 42, Training loss/acc: 0.40/0.82: 100%|██████████| 521/521 [00:28<00:00, 18.07batch/s]\n",
      "Epoch: 42, Validation loss/acc: 0.37/0.84: 100%|██████████| 53/53 [00:00<00:00, 97.89batch/s]\n",
      "Epoch: 43, Training loss/acc: 0.39/0.82: 100%|██████████| 521/521 [00:27<00:00, 18.81batch/s]\n",
      "Epoch: 43, Validation loss/acc: 0.37/0.83: 100%|██████████| 53/53 [00:00<00:00, 114.12batch/s]\n",
      "Epoch: 44, Training loss/acc: 0.40/0.82: 100%|██████████| 521/521 [00:28<00:00, 17.99batch/s]\n",
      "Epoch: 44, Validation loss/acc: 0.35/0.84: 100%|██████████| 53/53 [00:00<00:00, 117.70batch/s]\n",
      "Epoch: 45, Training loss/acc: 0.39/0.83: 100%|██████████| 521/521 [00:27<00:00, 18.74batch/s]\n",
      "Epoch: 45, Validation loss/acc: 0.37/0.85: 100%|██████████| 53/53 [00:00<00:00, 99.10batch/s]\n",
      "Epoch: 46, Training loss/acc: 0.39/0.83: 100%|██████████| 521/521 [00:27<00:00, 18.70batch/s]\n",
      "Epoch: 46, Validation loss/acc: 0.45/0.81: 100%|██████████| 53/53 [00:00<00:00, 115.36batch/s]\n",
      "Epoch: 47, Training loss/acc: 0.38/0.83: 100%|██████████| 521/521 [00:27<00:00, 19.12batch/s]\n",
      "Epoch: 47, Validation loss/acc: 0.41/0.81: 100%|██████████| 53/53 [00:00<00:00, 120.19batch/s]\n",
      "Epoch: 48, Training loss/acc: 0.39/0.83: 100%|██████████| 521/521 [00:27<00:00, 18.64batch/s]\n",
      "Epoch: 48, Validation loss/acc: 0.36/0.84: 100%|██████████| 53/53 [00:00<00:00, 97.34batch/s]\n",
      "Epoch: 49, Training loss/acc: 0.38/0.83: 100%|██████████| 521/521 [00:29<00:00, 17.70batch/s]\n",
      "Epoch: 49, Validation loss/acc: 0.35/0.85: 100%|██████████| 53/53 [00:00<00:00, 115.01batch/s]\n",
      "Epoch: 50, Training loss/acc: 0.37/0.83: 100%|██████████| 521/521 [00:27<00:00, 19.11batch/s]\n",
      "Epoch: 50, Validation loss/acc: 0.39/0.83: 100%|██████████| 53/53 [00:00<00:00, 114.17batch/s]\n"
     ]
    }
   ],
   "source": [
    "n_batch = len(df_train) // FLAGS.batch_size + 1 # standard way - look all samples per epoch\n",
    "\n",
    "early_stop = EarlyStopping(patience=10)\n",
    "model_checkpt = Model_checkpoint(model_name=model_graph_name, save_best_only=True)\n",
    "reduce_lr = ReduceLROnPlateau(lr=FLAGS.lr, factor=0.5, patience=3)\n",
    "\n",
    "callback_dict = {\n",
    "    'on_session_begin':[], # start of a session\n",
    "    'on_batch_begin':[], # start of a training batch\n",
    "    'on_batch_end':[], # end of a training batch\n",
    "    'on_epoch_begin':[], # start of a epoch\n",
    "    'on_epoch_end':[early_stop, reduce_lr, model_checkpt], # end of a epoch\n",
    "    'on_session_end':[] # end of a session\n",
    "    }\n",
    "callback_manager = Run_collected_functions(callback_dict)\n",
    "\n",
    "\n",
    "# -------------------------- #\n",
    "global_train_loss, global_train_acc = [], []\n",
    "global_valid_loss, global_valid_acc = [], []\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    saver = tf.train.Saver()\n",
    "    sess.run([tf.global_variables_initializer()])\n",
    "    \n",
    "    \"\"\"\n",
    "    epoch_bar = tqdm(range(FLAGS.epochs), \n",
    "                     desc = \"Train epoch\", \n",
    "                     unit = \"Epoch\")\n",
    "    \"\"\"\n",
    "    epoch_bar = range(FLAGS.epochs)\n",
    "    for i in epoch_bar:\n",
    "        \"\"\"\n",
    "        if i == 0:\n",
    "            epoch_bar.set_description(\"Training loss/acc: %.2f/%.2f ;Validation: %.2f/%.2f\" % \n",
    "                                  (0.0,0.0,0.0,0.0))\n",
    "        else:\n",
    "            epoch_bar.set_description(\"Training loss/acc: %.2f/%.2f ;Validation: %.2f/%.2f\" % \n",
    "                                  (global_train_loss[-1], global_train_acc[-1], global_valid_loss[-1], global_valid_acc[-1]))\n",
    "        \"\"\"\n",
    "        train_epoch_loss, train_epoch_acc = [], []\n",
    "        train_batch_bar = tqdm(range(n_batch), \n",
    "                               desc = \"Training batch\", \n",
    "                               unit = \"batch\", \n",
    "                               leave = True)\n",
    "        for j in train_batch_bar:\n",
    "            x_, y_ = data_gen.train_queue.get()\n",
    "            \n",
    "            batch_loss, batch_acc, _ = sess.run([total_loss, accuracy_op, optim_op], \n",
    "                                                feed_dict = {a_in: x_, \n",
    "                                                                     y_holder: y_, \n",
    "                                                                     tf.keras.backend.learning_phase(): 1,\n",
    "                                                                     drp_holder: 0.2})\n",
    "            train_epoch_loss.append(batch_loss)\n",
    "            train_epoch_acc.append(batch_acc)\n",
    "            current_train_loss = np.mean(train_epoch_loss)\n",
    "            current_train_acc = np.mean(train_epoch_acc)\n",
    "            train_batch_bar.set_description('Epoch: %i, Training loss/acc: %.2f/%.2f' % (int(i+1),current_train_loss, current_train_acc))\n",
    "            \n",
    "        \n",
    "        global_train_loss.append(current_train_loss)\n",
    "        global_train_acc.append(current_train_acc)\n",
    "        \n",
    "        valid_epoch_loss, valid_epoch_acc = [], []\n",
    "        \n",
    "        valid_step = range(len(df_val) // FLAGS.batch_size + 1)\n",
    "        valid_batch_bar = tqdm(valid_step, \n",
    "                               desc = \"Valid batch\", \n",
    "                               unit = \"batch\", leave = True)\n",
    "        \n",
    "        #valid_batch_bar = range(len(df_val) // FLAGS.batch_size + 1)\n",
    "        for j in valid_batch_bar:\n",
    "            this_val_loss, this_val_acc = sess.run([total_loss, accuracy_op], \n",
    "                                                       feed_dict = {a_in: x_val[j*FLAGS.batch_size : (j+1) * FLAGS.batch_size], \n",
    "                                                                            y_holder: y_val[j*FLAGS.batch_size : (j+1) * FLAGS.batch_size],\n",
    "                                                                            tf.keras.backend.learning_phase(): 0,\n",
    "                                                                            drp_holder: 0.0} )\n",
    "            valid_epoch_loss.append(this_val_loss)\n",
    "            valid_epoch_acc.append(this_val_acc)\n",
    "            \n",
    "            if j == np.max(valid_step):\n",
    "                current_valid_loss = np.mean(valid_epoch_loss)\n",
    "                current_valid_acc = np.mean(valid_epoch_acc)\n",
    "                valid_batch_bar.set_description('Epoch: %i, Validation loss/acc: %.2f/%.2f' % (int(i+1), current_valid_loss, current_valid_acc))\n",
    "\n",
    "        # \n",
    "        global_valid_loss.append(current_valid_loss)\n",
    "        global_valid_acc.append(current_valid_acc)\n",
    "        \n",
    "        #\n",
    "        callback_manager.run_on_epoch_end(val_loss = current_valid_loss,\n",
    "                                          sess = sess,\n",
    "                                          saver = saver,\n",
    "                                          nth_epoch = i)\n",
    "        if early_stop.stop:\n",
    "            print(\"EarlyStop!\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n8uDunHMRyIO7c85FoP8HUUTqcI/jUoAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd578206cf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD8CAYAAACb4nSYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd561884278>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(len(global_train_loss)), global_train_loss, 'b', label = 'training loss')\n",
    "plt.plot(range(len(global_valid_loss)), global_valid_loss, 'r', label = 'validation loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(range(len(global_train_acc)), global_train_acc, 'b', label = 'training accuracy')\n",
    "plt.plot(range(len(global_valid_acc)), global_valid_acc, 'r', label = 'validation accuracy')\n",
    "plt.legend(loc = 4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./result/model.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./result/model.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run predict on Test mode\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.86"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# restore and prediction\n",
    "n_pickup = 100\n",
    "pred_id = np.random.choice(np.arange(len(x_val)), replace=False, size=n_pickup)\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, model_graph_name + \".ckpt\")\n",
    "    print(\"Run predict on Test mode\")\n",
    "    pred_res = sess.run(out, \n",
    "                        feed_dict = {a_in: x_val[pred_id], \n",
    "                                     tf.keras.backend.learning_phase(): 0,\n",
    "                                     drp_holder: 0.0} )\n",
    "# Accuracy\n",
    "np.sum(pred_res.argmax(axis = 1) == y_val[pred_id].argmax(axis = 1)) / len(pred_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 885, 2407, 2262, 2313,  688,  342, 1457, 2246,  552,  946])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "??np.random.choice"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {
    "6b1438b3075f49289cfcf03a4fce2ccb": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    },
    "ab7848b490e5454e9a42f439a6ef6b31": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    },
    "e0e3b0d66b1e47c4ade6c276bacc5c55": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
